{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validate --> Train, Test\n",
    "\n",
    "In this exercise, you will perform empirical comparison of the results of a ten-fold cross validated model with a fully trained model.\n",
    "\n",
    "## Notes and Guidelines\n",
    "* Read a dataset from disk and use it for a classification task.\n",
    "* Construct a Gaussian Naive Bayes classifier and fit it to the phoneme dataset provided.\n",
    "* Save and re-load a trained classifier.\n",
    "* Compare K-fold cross-validation scores with the success rate of a fully-trained model.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "* Dataset acquired from [KEEL](http://sci2s.ugr.es/keel/dataset.php?cod=105), an excellent resource for finding 'toy' datasets (and a few more serious ones).\n",
    "    * A description of the dataset is provided at the above link - **read it.**\n",
    "    * Excerpt: \n",
    "    *The aim of this dataset is to distinguish between nasal (class 0) and oral sounds (class 1).\n",
    "    The class distribution is 3,818 samples in class 0 and 1,586 samples in class 1.\n",
    "    The phonemes are transcribed as follows: sh as in she, dcl as in dark, iy as the vowel in she, aa as the vowel in dark, and ao as the first vowel in water.*\n",
    "    \n",
    "* It is not necessary to fully understand the nature or context of the values in the dataset - only that there are five columns of input (featural) data and one column of output (class) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Handling imports and dataset inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.externals import joblib as jb\n",
    "\n",
    "# locate dataset\n",
    "DATASET = '/dsa/data/all_datasets/phoneme.csv'  # phoneme classification dataset\n",
    "assert os.path.exists(DATASET)  # check if the file actually exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing DataFrame from raw dataset\n",
    "\n",
    "<span style=\"background:yellow\">**Note**</span>: Variable `dataset` should be used for the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_table() is like read_csv(), but generalized for delimited file formats\n",
    "# and calling .sample() with a fraction of 1 shuffles the data\n",
    "dataset = pd.read_table(DATASET, sep=',', engine='c', header=0).sample(frac=1)\n",
    "\n",
    "# verify dataset shape\n",
    "print(\"Dataset shape: \", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The below is only necessary if you are interested in visualizing\n",
    "the data or providing neatly-labeled output within the program.\n",
    "\n",
    "# extract labels from column headers\n",
    "phonemes = dataset.columns[0:5].tolist()  # Feature labels\n",
    "labels = {0: 'Nasal', 1: 'Oral'}  # Class labels\n",
    "\"\"\"\n",
    "\n",
    "# extract target data from primary data frame\n",
    "X = dataset.iloc[:, 0:5]  # iloc is used here for numeric indexing\n",
    "y = dataset.loc[:, \"Class\"]  # loc can be used for label-based indexing\n",
    "\n",
    "# split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(\"Training shapes (X, y): \", X_train.shape, y_train.shape)\n",
    "print(\"Testing shapes (X, y): \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the classifier and running automated cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code below this line\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier and pickling to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code below this line\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpickling the model and making predictions\n",
    "\n",
    "#### Fill in the `# ???` with proper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code below this line\n",
    "# --------------------------\n",
    "\n",
    "# load pickled model\n",
    "loaded_model = # ???\n",
    "\n",
    "# make predictions with freshly loaded model\n",
    "predictions = # ???\n",
    "\n",
    "# verify input and output shape are appropriate\n",
    "print(\"Input vs. output shape:\")\n",
    "print(X_test.shape, predictions.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing final performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tally up right + wrong 'guesses' by model\n",
    "true, false = 0, 0\n",
    "for i, j in zip(y_test, predictions):\n",
    "    # print(i, j)\n",
    "    if i == j:\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "\n",
    "# report results numerically and by percentage\n",
    "true_percent = true / (true + false) * 100\n",
    "print(\"Correct guesses: \" + str(true) + \"\\nIncorrect guesses: \" + str(false))\n",
    "print(\"Percent correct: \" + str(true_percent))\n",
    "\n",
    "# compare to average of cross-validation scores\n",
    "avg_cv = np.sum(scores) / len(scores) * 100\n",
    "print(\"Percent cross-validation score (10 folds, average): \" + str(avg_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure performance using Scikit Learn modules \n",
    "#### (see Module 1 labs)\n",
    "Compute and display the following:\n",
    " 1. Compute Confusion Matrix\n",
    " 1. Accuracy\n",
    " 1. Precision\n",
    " 1. $F_1$-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code below this line\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions ?\n",
    "\n",
    "How did your trained model perform relative to your expectations based on the cross-validation?\n",
    "Provide your answer in the cell below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Add your answer below this comment\n",
    "# -----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
