{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Cross-Validation\n",
    "\n",
    "In this lab you will learn about another important methodology for evaluating the machine learning model, \n",
    "namely **cross-validation**,\n",
    "which involves the splitting dataset into multiple folds then validate on one of them after training the model on the rest of the folds.\n",
    "This establishes a reliable performance measure that assesses how the model will likely to generalize to an independent data set.\n",
    "Cross-validation is widely used for estimating test error for the following reasons:\n",
    "\n",
    "1. Provides less biased evaluation, which in turn, helps you reduce overfitting.\n",
    "2. Provides reliable way to validate model when no explicit validation set is made available.\n",
    "\n",
    "We are going to use **Gaussian Naive Bayes model** to fit the **red wine quality** dataset and create 5-fold and 10-fold cross-validation then compare.\n",
    "There are different variations of cross-validation and we will take a closer look into **K-fold cross-validation**.\n",
    "\n",
    "sklearn API reference:\n",
    "\n",
    "+ [sklearn.model_selection.cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Uncomment following line to view original output.\n",
    "# np.random.seed(18937)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Load dataset from files into Panda data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset location\n",
    "DATASET = '/dsa/data/all_datasets/wine-quality/winequality-red.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "# Load and shuffle\n",
    "dataset = pd.read_csv(DATASET, sep=';').sample(frac = 1).reset_index(drop=True)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation with sklearn\n",
    "\n",
    "In this example, we use a few of the feature columns as input **X** and the `quality` column as output **y**.\n",
    "Then perform a 5-fold cross-validation using **cross_val_score()**,\n",
    "which splits the data into 5 folds (based on the **cv** argument).\n",
    "Then for each fold it fits the data on 4 folds and scores the 5th fold.\n",
    "Then it gives you the 5 scores from which you can calculate a mean and variance for the score.\n",
    "This potentially allows you to cross-validate in order to tune parameters and get an estimate of the score. \n",
    "\n",
    "Note that the cross-validation process involves fitting the model by definition,\n",
    "so you don't need to fit the model prior to cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "    # Convert the loaded dataset (data frame) into a multi-dimensional array with columns 1,2,6,7,10 as input data\n",
    "X = np.array(dataset.iloc[:,:-1])[:, [1,2,6,9,10]]\n",
    "    # Slice out the quality column as the expected value.\n",
    "y = np.array(dataset.quality)\n",
    "\n",
    "# Do the cross-validation\n",
    "sklearn.model_selection.cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above shows 5 scores from the 5-fold cross-validation.\n",
    "For each round of cross-validation, the model was fit on 4 of the folds and scored on the one held out.\n",
    "You should see different model scores, five in this case.\n",
    "This indicates that certain training instances validated against their test fold better than others.\n",
    "\n",
    "Next, we will be sure to get very familiarized with this workflow by implementing our own. \n",
    "Then discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create folds\n",
    "\n",
    "The original dataset should be **randomly** sampled into equal-sized folds.\n",
    "But here the random resample was already done when we loaded the dataset previously.\n",
    "\n",
    "Now we split the data into 5 folds. \n",
    "This can be achieved using **array_split()** from numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.array_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_folds = np.array_split(X, 5) # split the array into 5 chunks by rows chunks (axis = 0)\n",
    "[i.shape for i in X_folds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have around 1600 entries and 5 types of features in the input, so we have confirmed their shapes look good after splitting.\n",
    "The following demonstrates how **array_split()** behaves on dataset size that aren't evenly divisible by number of folds.\n",
    "This has ensured that the folds are divided as evenly as possible.\n",
    "Same could be achieved via array slicing, but would look more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(120, 130):\n",
    "    print(t, 'entries into', 10, 'folds:', [i.shape[0] for i in np.array_split(np.zeros(t), 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for Y folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_folds = np.array_split(y, 5)\n",
    "[i.shape for i in y_folds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "For each round **i**:\n",
    "1. concatenate all folds _except fold **#i**_ to create the training set and fit the model\n",
    "2. then score the model based on the fold **#i** that was withheld from training.\n",
    "\n",
    "Each round is similar to what's been covered in Module 1: Train and Validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    X_train = np.concatenate([X_folds[j] for j in range(5) if j!=i])\n",
    "    X_test = X_folds[i]\n",
    "    y_train = np.concatenate([y_folds[j] for j in range(5) if j!=i])\n",
    "    y_test = y_folds[i]\n",
    "    print('CV', i,\n",
    "          'X_train', X_train.shape, 'X_test', X_test.shape,\n",
    "          'y_train', y_train.shape, 'y_test', y_test.shape)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Score:', round(model.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting things together\n",
    "\n",
    "Now we can replicate the general functionality of **cross_val_score()** from sklearn, \n",
    "and have a better understanding of the cross-validation workflow.\n",
    "\n",
    "**Note:** As an exercise to help you get in the habit of congnitively processing code you read, instead of just running it, \n",
    "you could comment each code line with your interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score(model, X, y, cv = 10):\n",
    "    X_folds = np.array_split(X, cv)\n",
    "    Y_folds = np.array_split(y, cv)\n",
    "    \n",
    "    for i in range(cv):\n",
    "        X_train = np.concatenate([X_folds[j] for j in range(cv) if j!=i])\n",
    "        X_test = X_folds[i]\n",
    "        y_train = np.concatenate([Y_folds[j] for j in range(cv) if j!=i])\n",
    "        y_test = y_folds[i]\n",
    "        model.fit(X_train, y_train)\n",
    "        yield model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Our CV:', list(cross_val_score(model, X, y, cv=5)))\n",
    "print('sklearn CV:', sklearn.model_selection.cross_val_score(model, X, y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-fold vs 10-fold cross-validation\n",
    "\n",
    "While the implementation of **k**-fold cross-validation is straightforward, \n",
    "it's important that we understand the strengths and limitations of this methodology before its application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = sklearn.model_selection.cross_val_score(model, X, y, cv=5)\n",
    "s10 = sklearn.model_selection.cross_val_score(model, X, y, cv=10)\n",
    "print('5-fold mean', np.mean(s5), 'variance', np.var(s5))\n",
    "print('10-fold mean', np.mean(s10), 'variance', np.var(s10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('5-fold scores', s5)\n",
    "print('10-fold scores', s10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a known issue that cross-validated scores can have large variance especially on smaller datasets.\n",
    "Here we compare 5-fold vs 10-fold cross-validation, and 10-fold cross-validation has shown higher variance. \n",
    "\n",
    "+ Larger number of folds usually means less bias. However, as we use more folds, the testing dataset also gets smaller, and variance of cross-validation scores increases.\n",
    "+ Too large number of folds mean that only a low number of sample combinations is possible, thus limiting the number of iterations that are different. That is to say the training data for each round will have large overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Second argument is a list-comprehension generated by running the for-loop of cross_val_score()\n",
    "plt.scatter([3,5,6,7,8,9,10],\n",
    "    [np.var(sklearn.model_selection.cross_val_score(model, X, y, cv=i))*100 for i in [3,5,6,7,8,9,10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above figure shows how variance of scores changes with respect to number of folds used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to lower the variance of the cross-validation result, you should iterate the cross-validation with new random splits.\n",
    "If possible, use a number of folds that is a divisor of the sample size.\n",
    "\n",
    "_ Limitations of cross-validation are mostly relevant to small datasets. _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab we learned about:\n",
    "\n",
    "+ Cross-validation workflow and its implementation\n",
    "+ Compared 5-fold vs 10-fold cross-validation\n",
    "+ Strengths and limitations of k-fold validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
