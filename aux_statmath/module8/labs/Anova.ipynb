{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anova (Analysis of Variance)\n",
    "\n",
    "ANOVA is a statistical method for making multiple group comparisons. \n",
    "It provides an easy way to eliminate variables that contribute little in predicting the dependent variable. \n",
    "ANOVA tests the features in general rather than specific differences in the mean of the features. \n",
    "In this notebook, we will focus on one way ANOVA. \n",
    "In one way ANOVA, we will compare the effects of a single independent variable. \n",
    "\n",
    "It is called analysis of variance because it involves taking the entire variance \n",
    "in a dataset and divides the source of variance into different components. \n",
    "Each individual score is the product of the mean of the population, \n",
    "the effects of the independent variable, and random error.\n",
    "\n",
    "There are three components of variance. \n",
    "**Total variance** is the variance of all subjects regardless of the group to which they belong. \n",
    "Total variance is further partitioned in to **between-groups variance** and **within-groups variance**. \n",
    "Between-groups variance is the index of differences among group means due to the effects \n",
    "of the independent variable and random error. \n",
    "It represents the variance between the group’s means. \n",
    "Within-groups variance represents the differences among subjects in groups due to random error. \n",
    "It represents the variance among subjects within each group of the experiment. \n",
    "The variance for both between-groups and within-groups is computed as their sum of squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "The F-ratio metric determines if differences among group means are due to random variation \n",
    "or if the differences are due to nonchance. \n",
    "It is expressed as\n",
    "\n",
    "$$F = \\frac{between-group variance}{within-group variance}$$\n",
    "\n",
    "Anova helps to determine whether the means from more than two populations or groups are equal or not. \n",
    "In another words whether the difference in means is statistically significant or not. \n",
    "If the ANOVA F-test shows there is a significant difference in means between the groups we may \n",
    "want to perform multiple comparisons between all pair-wise means to determine how they differ.\n",
    "\n",
    "Let's analyze the auto miles per gallon dataset to find how variables are similar are dissimilar to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the auto-mpg dataset from '/dsa/data/all_datasets/auto-mpg/' ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto_data=read.csv(\"/dsa/data/all_datasets/auto-mpg/auto-mpg.csv\")\n",
    "head(auto_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(auto_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One way between ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame null hypothesis as\n",
    "\n",
    "$H_0$:  No significant difference exist in miles per gallon among vehicles of different origin\n",
    "\n",
    "$H_1$:  Significant difference exist in miles per gallon among vehicles of different origin\n",
    "\n",
    "Use `aov()` function in R to test the null hypothesis to figure out whether to reject or fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a graph to compare the means of mpg across groups. The independent variable should be a factor to create group wise plots. So, let's convert the variable origin into a factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto_data$origin=as.factor(auto_data$origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "ggplot(auto_data,aes(origin,mpg))+geom_boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot it appears that the average mpg for vehicles from origin 3 is higher compared to other origins. Origin 1 has the lowest average mpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General form for aov() is aov(response ~ factor, data=data_name)\n",
    "# where response represents the response variable and factor the variable \n",
    "# that separates the data into groups. \n",
    "# Both variables should be contained in the dataframe called data_name.\n",
    "\n",
    "fit <- aov(mpg ~ origin, data=auto_data)\n",
    "summary(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read API documentation\n",
    "help(aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above results the F-statistic is 98.54 with a p-value almost equal to 0.\n",
    "The null hypothesis that \"no significant difference exist in miles per gallon among \n",
    "vehicles of different origin\" can be clearly rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the means\n",
    "# model.tables() computes summary tables for model fits, especially complex aov fits.\n",
    "# type = \"means\" give tables of the mean response for each combinations of levels of the factors in a term.\n",
    "model.tables(fit, \"means\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above gave an average mpg for 3 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(model.tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two way between ANOVA\n",
    "\n",
    "Can we test if `mpg` is explained by `origin`, `horsepower` and _also by the interaction between them_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Two Way Factorial Design \n",
    "\n",
    "# Independent variable: origin\n",
    "# Independent variable: horsepower\n",
    "# Dependent variable: mpg\n",
    "\n",
    "# There are two different ways of performing 2-way anova. \n",
    "# Note: The formula for the model\n",
    "fit2 <- aov(mpg ~ origin*horsepower, data=auto_data)\n",
    "summary(fit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "The formula in the model is combining terms using the __`*`__ symbol instead of the __`+`__ as we saw in regression and classification.\n",
    "\n",
    "```R\n",
    "mpg ~ origin*horsepower\n",
    "```\n",
    "\n",
    "### Multiple comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANOVA F-test tells whether there are significant differences in the K population means.\n",
    "It does not tell us anything about how they differ. \n",
    "The `pairwise.t.test` function computes the pair-wise comparisons between group means with corrections for multiple testing. Its usage is: \n",
    "\n",
    "```R\n",
    "pairwise.t.test(reponse, \n",
    "                factor, p.adjust = method, \n",
    "                alternative = c(\"two.sided\",\"less\", \"greater\")\n",
    "                )\n",
    "```\n",
    "\n",
    "\n",
    "Here, `p.adjust` is the correction method (e.g., “Bonferroni”).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(pairwise.t.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(auto_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairwise.t.test(auto_data$mpg, auto_data$origin,p.adjust=\"bonferroni\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table shows there is a good difference in means between \n",
    "origins 2 and 3 with a p-value of 0.046, \n",
    "but both are significantly different from origin 1 with p-values almost equal to 0. \n",
    "We can confidently say that the average mpg is significantly different for origin 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Tukey's Method\n",
    "\n",
    "Tukey's method also known as _Tukey's Honest Significant Differences test_ is another multiple comparisons procedure. \n",
    "`TukeyHSD()` creates a set of confidence intervals on the differences between means with \n",
    "the specified family-wise probability of coverage. \n",
    "The general form is `TukeyHSD(x, conf.level = 0.95)` where **x** is a fitted model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tukey = TukeyHSD(fit, conf.level = 0.95)\n",
    "Tukey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(TukeyHSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  graphical representation of the multiple confidence intervals\n",
    "plot(Tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results show that 2-1 and 3-1 differences are significant with p-values equal to zero, \n",
    "while 3-2 difference is large with p=0.04."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVAs with _within-subjects_ variables\n",
    "\n",
    "\n",
    "#### One-way within ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will generate test data for testing _within-subjects_ ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is a code defined table\n",
    "groceries = read.table(header=TRUE,text='\n",
    "subject            storeA  storeB  storeC  storeD\n",
    "lettuce              1.17    1.78    1.29    1.29\n",
    "potatoes             1.77    1.98    1.99    1.99\n",
    "milk                 1.49    1.69    1.79    1.59\n",
    "eggs                 0.65    0.99    0.69    1.09\n",
    "bread                1.58    1.70    1.89    1.89\n",
    "cereal               3.13    3.15    2.99    3.09\n",
    "ground.beef          2.09    1.88    2.09    2.49\n",
    "tomato.soup          0.62    0.65    0.65    0.69\n",
    "laundry.detergent    5.89    5.99    5.99    6.99\n",
    "aspirin              4.46    4.84    4.99    5.15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head(groceries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(groceries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For performing within-subjects ANOVA with a variable, \n",
    "the data should be in long format. Why?\n",
    "\n",
    "Because the response variable in this case is the `price` of the items which is \n",
    "listed in four columns (**wide format**). \n",
    "Each of these variables needs to be in ONE column (**long format**) of the data frame \n",
    "in order to use the `aov()` function.\n",
    "\n",
    "The data above is in wide format, so we have to convert it to long format first. \n",
    "Also, for there must be an identifier column for within-subjects ANOVA. \n",
    "In this case, it is subject. \n",
    "This identifier variable must be a factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groceries_stacked = stack(groceries)     # Stack the variables StoreA, storeB, storeC and store D\n",
    "groceries_stacked$subject = rep(rownames(groceries), 4)    # create the \"subject\" variable and repeat the names of groceries\n",
    "                                                           # 4 times for 4 store variables stacked.\n",
    "groceries_stacked$subject = factor(groceries_stacked$subject)            # Convert subject variable to a factor.\n",
    "colnames(groceries_stacked) = c(\"price\", \"store\", \"subject\")  # Gives names to the columns of dataframe groceries_stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head(groceries_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have the prices of all groceries stacked in a column, \n",
    "we can answer the question of which store we should shop at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with(groceries_stacked, t(tapply(price, store, sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the items in the sample, `storeA` had the lowest prices. \n",
    "We have to generalize our assertion that this price difference from `storeA` holds up in general.\n",
    "An error term should be supplied, that reflects the fact that the \"treatments are nested within subjects.\", \n",
    "that is the \"store\" effect within each, and where every \"subject\" (grocery item) can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aov_within = aov(price ~ store + Error(subject/store), data=groceries_stacked)\n",
    "summary(aov_within)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Revisit the aov documentation and review the use of the Error() \n",
    "help(aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The p-value of __0.0127__ suggests the prices in stores are different. \n",
    "Store and subject are the sources of variability. \n",
    "We are interested in the effect of \"store\". \n",
    "This variable effect is visible within each subject, i.e. nested within each subject. \n",
    "So the error term is \"_subject/store_\", which is read as \"store within subject.\" \n",
    "Once all the \"subject\" variability is taken out we are left with the main effect that is from \"store\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with(groceries_stacked, pairwise.t.test(x=price, g=store, p.adjust.method=\"none\", paired=T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pairwise.t.test` suggests all stores have different prices and show some variation in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unequal Samples Sizes in Anova:\n",
    "\n",
    "The only practical issue in one-way ANOVA is that very unequal sample sizes can affect the \n",
    "homogeneity of variance assumption.  \n",
    "ANOVA is considered robust to moderate departures from this assumption, \n",
    "but the departure needs to stay smaller when the sample sizes are very different.  \n",
    "According to Keppel (1993), there isn’t a good rule of thumb for the point at which \n",
    "unequal sample sizes make heterogeneity of variance a problem.\n",
    "\n",
    "Real issues with unequal sample sizes do occur in factorial ANOVA, \n",
    "if the sample sizes are confounded in the two (or more) factors.  \n",
    "For example, in a two-way ANOVA, \n",
    "let’s say that your two independent variables (factors) are age (young vs. old) and marital status (married vs. not).  \n",
    "If there are twice as many young people as old and the young group has a much larger percentage of \n",
    "singles than the older group, the effect of marital status cannot be distinguished from the effect of age.\n",
    "\n",
    "The effectiveness of the statistical test (sometimes referred to as _power_) is based on the smallest sample size, \n",
    "so while it doesn’t hurt power to have more observations in the larger group, it doesn’t help either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Problem of Confounding\n",
    "\n",
    "Whether by design, accident, or necessity, the number of subjects in each of the conditions \n",
    "in an experiment may not be equal. \n",
    "For example, the sample sizes for the \"Bias Against Associates of the Obese\" case study are shown in Table 1. \n",
    "Although the sample sizes were approximately equal, the \"Acquaintance Typical\" condition had the most subjects. Since _n_ is used to refer to the sample size of an individual group, \n",
    "designs with unequal sample sizes are sometimes referred to as designs with unequal n.\n",
    "\n",
    "<img src=\"../images/table_1.PNG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider an absurd design to illustrate the main problem caused by unequal n. \n",
    "\n",
    "Suppose an experimenter were interested in the effects of diet and exercise on cholesterol. \n",
    "The sample sizes are shown in Table 2.\n",
    "\n",
    "<img src=\"../images/table_2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What makes this example absurd is that there are no subjects in either the \n",
    "\"Low-Fat No-Exercise\" condition or the \"High-Fat Moderate-Exercise\" condition. \n",
    "The hypothetical data showing change in cholesterol are shown in Table 3.\n",
    "\n",
    "<img src=\"../images/table_3.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last column shows the mean change in cholesterol for the two Diet conditions, \n",
    "whereas the last row shows the mean change in cholesterol for the two Exercise conditions. \n",
    "The value of -15 in the lower-right-most cell in the table is the mean of all subjects.\n",
    "\n",
    "We see from the last column that those on the low-fat diet lowered their cholesterol an average of 25 units, \n",
    "whereas those on the high-fat diet lowered theirs by only an average of 5 units. \n",
    "However, there is no way of knowing whether the difference is due to diet or to exercise since every \n",
    "subject in the low-fat condition was in the moderate-exercise condition and every subject \n",
    "in the high-fat condition was in the no-exercise condition. \n",
    "Therefore, Diet and Exercise are completely confounded. \n",
    "The problem with unequal n is that it causes confounding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted and Unweighted Means\n",
    "\n",
    "The difference between weighted and unweighted means is a difference critical for \n",
    "understanding how to deal with the confounding resulting from unequal n.\n",
    "\n",
    "Weighted and unweighted means will be explained using the data shown in Table 4. \n",
    "Here, Diet and Exercise are confounded because 80% of the subjects in the low-fat \n",
    "condition exercised as compared to 20% of those in the high-fat condition. \n",
    "However, there is not complete confounding as there was with the data in Table 3.\n",
    "\n",
    "The weighted mean for \"Low Fat\" is computed as the mean of the \"Low-Fat Moderate-Exercise\" \n",
    "mean and the \"Low-Fat No-Exercise\" mean, weighted in accordance with sample size.\n",
    "To compute a weighted mean, you multiply each mean by its sample size and divide by N, \n",
    "the total number of observations. \n",
    "Since there are four subjects in the \"Low-Fat Moderate-Exercise\" condition and one \n",
    "subject in the \"Low-Fat No-Exercise\" condition, \n",
    "the means are weighted by factors of 4 and 1 as shown below, where $M_w$ is the weighted mean.\n",
    "\n",
    "<img src=\"../images/a.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted mean for the low-fat condition is also the mean of all five scores in this condition. \n",
    "Thus if you ignore the factor \"Exercise,\" you are implicitly computing weighted means.\n",
    "\n",
    "The unweighted mean for the low-fat condition ($M_u$) is simply the mean of the two means.\n",
    "\n",
    "<img src=\"../images/b.PNG\">\n",
    "\n",
    "<img src=\"../images/table_4.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to evaluate the main effect of Diet is to compare the weighted mean for the \n",
    "low-fat diet (-26) with the weighted mean for the high-fat diet (-4). \n",
    "This difference of -22 is called \"the effect of diet ignoring exercise\" and is misleading since \n",
    "most of the low-fat subjects exercised and most of the high-fat subjects did not. \n",
    "However, the difference between the unweighted means of -15.625 (-23.750 minus -8.125) is not \n",
    "affected by this confounding and is therefore a better measure of the main effect. \n",
    "In short, weighted means ignore the effects of other variables (exercise in this example) and result in confounding; \n",
    "unweighted means control for the effect of other variables and therefore eliminate the confounding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of Sums of Squares\n",
    "\n",
    "In multi-factor ANOVA when there are unequal sample sizes the sum of squares total is not equal \n",
    "to the sum of the sums of squares for all the other sources of variation. \n",
    "This is because the confounded sums of squares are not apportioned to any source of variation. \n",
    "For the data in Table 4, the sum of squares for Diet is 390.625, the sum of squares for Exercise is 180.625, \n",
    "and the sum of squares confounded between these two factors is 819.375 \n",
    "(the calculation of this value is beyond the scope of this discussion). \n",
    "\n",
    "In the ANOVA Summary Table shown in Table 5, this large portion of the sums of squares is not \n",
    "apportioned to any source of variation and represents the \"missing\" sums of squares. \n",
    "That is, if you add up the sums of squares for Diet, Exercise, D x E, and Error, you get 902.625. \n",
    "If you add the confounded sum of squares of 819.375 to this value, you get the total sum of squares of 1722.000. When confounded sums of squares are not apportioned to any source of variation, \n",
    "the sums of squares are called _Type III sums of squares_. \n",
    "Type III sums of squares are, by far, the most common and if sums of squares are not otherwise labeled, \n",
    "it can safely be assumed that they are Type III.\n",
    "\n",
    "<img src=\"../images/table_5.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all confounded sums of squares are apportioned to sources of variation, \n",
    "the sums of squares are called _Type I_ sums of squares. \n",
    "The order in which the confounded sums of squares are apportioned is determined \n",
    "by the order in which the effects are listed. \n",
    "The first effect gets any sums of squares confounded between it and any of the other effects. \n",
    "The second gets the sums of squares confounded between it and subsequent effects, \n",
    "but not confounded with the first effect, etc. \n",
    "The Type I sums of squares are shown in Table 6. \n",
    "As you can see, with Type I sums of squares, the sum of all sums of squares is the total sum of squares.\n",
    "\n",
    "<img src=\"../images/table_6.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In _Type II_ sums of squares, sums of squares confounded between main effects are not apportioned to any source of variation,\n",
    "whereas sums of squares confounded between main effects and interactions are apportioned to the main effects.\n",
    "In our example, there is no confounding between the D x E interaction and either of the main effects. \n",
    "Therefore, the Type II sums of squares are equal to the Type III sums of squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which Type of Sums of Squares to Use\n",
    "\n",
    "Type I sums of squares allow the variance confounded between two main effects to be apportioned to one of the main effects. \n",
    "Unless there is a strong argument for how the confounded variance should be apportioned \n",
    "(which is rarely, if ever, the case), Type I sums of squares are not recommended.\n",
    "\n",
    "There is not a consensus about whether Type II or Type III sums of squares is to be preferred. \n",
    "On the one hand, if there is no interaction, then Type II sums of squares will be more powerful for two reasons: \n",
    "(1) variance confounded between the main effect and interaction is properly assigned to the main effect and \n",
    "(2) weighting the means by sample sizes gives better estimates of the effects. \n",
    "To take advantage of the greater power of Type II sums of squares, \n",
    "some have suggested that if the interaction is not significant, then Type II sums of squares should be used. \n",
    "Maxwell and Delaney (2003) caution that such an approach could result in a Type II error in the test of the interaction. \n",
    "That is, it could lead to the conclusion that there is no interaction in the population when there really is one. This, in turn, would increase the Type I error rate for the test of the main effect. \n",
    "As a result, their general recommendation is to use Type III sums of squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maxwell and Delaney (2003) recognized that some researchers prefer Type II sums of squares when there are strong \n",
    "theoretical reasons to suspect a lack of interaction and the p-value is much higher than the typical α level of 0.05. \n",
    "However, this argument for the use of Type II sums of squares is not entirely convincing. \n",
    "As Tukey (1991) and others have argued, it is doubtful that any effect, whether a main effect or an interaction, \n",
    "is exactly 0 in the population. \n",
    "Incidentally, Tukey argued that the role of significance testing is to determine whether a confident \n",
    "conclusion can be made about the direction of an effect, not simply to conclude that an effect is not exactly 0.\n",
    "\n",
    "Finally, if one assumes that there is no interaction, then an ANOVA model with no interaction term should be used rather than Type II sums of squares in a model that includes an interaction term. \n",
    "(Models without interaction terms are beyond this course material).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are situations in which Type II sums of squares are justified even if there is strong interaction. \n",
    "This is the case because the hypotheses tested by Type II and Type III sums of squares are different, \n",
    "and the choice of which to use should be guided by which hypothesis is of interest. \n",
    "Recall that Type II sums of squares weight cells based on their sample sizes whereas Type III sums of squares weight all cells the same. \n",
    "Consider Figure 1 which shows data from a hypothetical A(2) x B(2) design. \n",
    "The sample sizes are shown numerically and are represented graphically by the areas of the endpoints.\n",
    "\n",
    "<img src=\"../images/figure_1.PNG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's consider the hypothesis for the main effect of B tested by the Type III sums of squares. \n",
    "Type III sums of squares weight the means equally and, for these data, the marginal means for b1 and b2 are equal:\n",
    "\n",
    "<img src=\"../images/c.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, there is no main effect of B when tested using Type III sums of squares. \n",
    "For Type II sums of squares, the means are weighted by sample size.\n",
    "\n",
    "<img src=\"../images/d.PNG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the weighted marginal mean for b2 is larger than the weighted marginal mean for b1, \n",
    "there is a main effect of B when tested using Type II sums of squares.\n",
    "\n",
    "The Type II and Type III analyses are testing different hypotheses. \n",
    "First, let's consider the case in which the differences in sample sizes arise because in the sampling of intact groups, \n",
    "the sample cell sizes reflect the population cell sizes (at least approximately). \n",
    "In this case, it makes sense to weight some means more than others and conclude that there is a main effect of B. \n",
    "This is the result obtained with Type II sums of squares. \n",
    "However, if the sample size differences arose from random assignment, \n",
    "and there just happened to be more observations in some cells than others, \n",
    "then one would want to estimate what the main effects would have been with equal sample sizes and, \n",
    "therefore, weight the means equally. \n",
    "With the means weighted equally, there is no main effect of B, the result obtained with Type III sums of squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unweighted Means Analysis\n",
    "\n",
    "Type III sums of squares are tests of differences in unweighted means. \n",
    "However, there is an alternative method to testing the same hypotheses tested using Type III sums of squares. \n",
    "This method, _unweighted means analysis_, is computationally simpler than the standard method\n",
    "but is an approximate test rather than an exact test. \n",
    "It is, however, a very good approximation in all but extreme cases. \n",
    "Moreover, it is exactly the same as the traditional test for effects with one degree of freedom. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Causes of Unequal Sample Sizes\n",
    "\n",
    "None of the methods for dealing with unequal sample sizes are valid if the experimental \n",
    "treatment is the source of the unequal sample sizes. \n",
    "Imagine an experiment seeking to determine whether publicly performing an embarrassing act \n",
    "would affect one's anxiety about public speaking. \n",
    "In this imaginary experiment, the experimental group is asked to reveal to a group of people \n",
    "the most embarrassing thing they have ever done. \n",
    "The control group is asked to describe what they had at their last meal. \n",
    "Twenty subjects are recruited for the experiment and randomly divided into two equal groups of 10, \n",
    "one for the experimental treatment and one for the control. \n",
    "Following their descriptions, subjects are given an attitude survey concerning public speaking. \n",
    "This seems like a valid experimental design. \n",
    "However, of the 10 subjects in the experimental group, four withdrew from the experiment \n",
    "because they did not wish to publicly describe an embarrassing situation. \n",
    "None of the subjects in the control group withdrew. \n",
    "Even if the data analysis were to show a significant effect, \n",
    "it would not be valid to conclude that the treatment had an effect because a likely alternative \n",
    "explanation cannot be ruled out; namely, \n",
    "subjects who were willing to describe an embarrassing situation differed from those who were not. \n",
    "Thus, the differential dropout rate destroyed the random assignment of subjects to conditions, \n",
    "a critical feature of the experimental design. \n",
    "No amount of statistical adjustment can compensate for this flaw.\n",
    "\n",
    "\n",
    "reference: http://onlinestatbook.com/2/analysis_of_variance/unequal.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a dataset with unequal sample sizes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a sample dataset with unequal sample sizes...\n",
    "site1 <- c(34,25,27,31,26,34,21)\n",
    "site2 <- c(33,35,31,31,42,33)\n",
    "site3 <- c(17,30,30,26,32,28,26,29)\n",
    "site4 <- c(28,33,31,27,32,33,40)\n",
    "\n",
    "Data <- data.frame(\n",
    "       Y=c(site1, site2, site3, site4),\n",
    "       Site =factor(rep(c(\"site1\", \"site2\", \"site3\", \"site4\"), times=c(length(site1), length(site2), length(site3), length(site4))))\n",
    "       )\n",
    "\n",
    "head(Data)\n",
    "tail(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's run an ANOVA on the dataset with unequal sample sizes...\n",
    "fm1 <- aov(Y~Site, data=Data)\n",
    "anova(fm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Means\n",
    "\n",
    "We can also calculate the weighted means of each site.\n",
    "\n",
    "Weighted means take into account the correlation between factors that results \n",
    "from having groups with different sample sizes. \n",
    "A weighted mean is calculated by simply adding up all of the values and dividing by the total number of values. \n",
    "Consequently, we can easily derive the weighted means for each group using our subset(data, condition), \n",
    "when necessary, and mean(data) functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use mean(data) to calculate the weighted means for each treatment group. \n",
    "#Since we created subsets above when we made our dataset, we don't have to use the subset function.\n",
    "#site 1 weighted mean\n",
    "mean(site1)\n",
    "#site 2 weighted mean\n",
    "mean(site2)\n",
    "#site 3 weighted mean\n",
    "mean(site3)\n",
    "#site 4 weighted mean\n",
    "mean(site4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that when applying weighted means, \n",
    "it is suggested that one uses Type I sums of squares (SS) in one's ANOVA (detailed above). \n",
    "Type I happens to be the default SS used in the standard anova(object) function in *R*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unweighted Means\n",
    "\n",
    "Now let’s turn to using unweighted means, \n",
    "which essentially ignore the correlation between the independent variables that arise from unequal sample sizes. \n",
    "An unweighted mean is calculated by taking the average of the individual group means. \n",
    "Thus, we can derive our unweighted means by summing the means of each level of our independent \n",
    "variables and dividing by the total number of levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use mean(data) and subset(data, condition) to calculate the unweighted means for each treatment group\n",
    "(mean(site1) + mean(site2) + mean(site3) + mean(site4)) / 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, when applying unweighted means, it is suggested that we use Type III sums of squares (SS) (discussed above) in our ANOVA. \n",
    "Type III SS can be set using the `type` argument in the `Anova(mod, type)` function, \n",
    "which is a member of the `car` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(Anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall above:  \n",
    "#  fm1 <- aov(Y~Site, data=Data) # internally builds a linear model\n",
    "fm2 <- lm(Y~Site, data=Data)\n",
    "Anova(fm2, type=\"II\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Anova(fm2, type=\"III\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests Supplimenting ANOVA:\n",
    "\n",
    "The null hypothesis tested in a one-factor ANOVA is that all the population means are equal. \n",
    "Stated more formally,\n",
    "\n",
    "<img src=\"../images/e.PNG\">\n",
    "\n",
    "where $H_0$ is the null hypothesis and $k$ is the number of conditions. \n",
    "When the null hypothesis is rejected, \n",
    "all that can be said is that at least one population mean is different from at least one other population mean.\n",
    "The methods for doing more specific tests to described _all pairwise comparisons among means_ apply here. \n",
    "Keep in mind that these tests are valid whether or not they are preceded by an ANOVA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Effects\n",
    "\n",
    "As shown below, significant main effects in multi-factor designs can be followed up\n",
    "in the same way as significant effects in one-way designs. \n",
    "Table 1 shows the data from an imaginary experiment with three levels of Factor A and two levels of Factor B.\n",
    "\n",
    "<img src=\"../images/table1_2.PNG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 2 shows the ANOVA Summary Table for these data. \n",
    "The significant main effect of A indicates that, in the population, \n",
    "at least one of the marginal means for A is different from at least one of the others.\n",
    "\n",
    "<img src=\"../images/table2_2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tukey HSD test can be used to test all pairwise comparisons among means in a one-factor \n",
    "ANOVA as well as comparisons among marginal means in a multi-factor ANOVA. \n",
    "The formula for the equal-sample-size case is shown below.\n",
    "\n",
    "<img src=\"../images/f.PNG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $M_i$ and $M_j$ are marginal means, MSE is the mean square error from the ANOVA, \n",
    "and $n$ is the number of scores each mean is based upon. \n",
    "For this example, MSE = 1.847 and $n = 8$ because there are eight scores at each level of A. \n",
    "\n",
    "The degrees of freedom is equal to the degrees of freedom error. \n",
    "For this example, $df = 18$. \n",
    "The results of the Tukey HSD test are shown in Table 3. \n",
    "The mean for $A_1$ is significantly lower than the mean for $A_2$ and the mean for $A_3$. \n",
    "The means for $A_2$ and $A_3$ are not significantly different.\n",
    "\n",
    "<img src=\"../images/table3_2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific comparisons among means are also carried out much the same way as shown in the \n",
    "relevant section on testing means. The formula for L is\n",
    "\n",
    "<img src=\"../images/g.PNG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "where $c_i$ is the coefficient for the $i^{th}$ marginal mean and $M_i$ is the $i^{th}$ marginal mean. \n",
    "For example, to compare $A_1$ with the average of $A_2$ and $A_3$, \n",
    "the coefficients would be 1, -0.5, -0.5. Therefore,\n",
    "\n",
    "<img src=\"../images/h.PNG\">\n",
    "\n",
    "To compute $t$, use:\n",
    "\n",
    "<img src=\"../images/i.PNG\">\n",
    "\n",
    "where MSE is the mean square error from the ANOVA and $n$ is the number of scores each \n",
    "marginal mean is based on (eight in this example). \n",
    "The degrees of freedom is the degrees of freedom error from the ANOVA and is equal to 18. \n",
    "We would find that the two-tailed probability value is 0.0005. \n",
    "Therefore, the difference between $A_1$ and the average of $A_2$ and $A_3$ is significant.\n",
    "\n",
    "#### Returning to our auto_mpg data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Recall:  fit <- aov(mpg ~ origin, data=auto_data)\n",
    "#\n",
    "# Tukey Honestly Significant Differences\n",
    "TukeyHSD(fit) # where fit comes from aov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactions\n",
    "\n",
    "The presence of a significant interaction makes the interpretation of the results more complicated. \n",
    "Since an interaction implies that the simple effects are different, \n",
    "the main effect as the mean of the simple effects does not tell the whole story. \n",
    "This section discusses how to describe interactions, \n",
    "proper and improper uses of simple effects tests, and how to test components of interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Describing Interactions\n",
    "\n",
    "A crucial first step in understanding a significant interaction is constructing an interaction plot. \n",
    "Figure 1 shows an interaction plot from data presented in the section on Multi-Factor ANOVA.\n",
    "\n",
    "<img src=\"../images/figure1_2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to describe the interaction in a clear and understandable way. \n",
    "This is often done by describing how the simple effects differed. \n",
    "Since this should be done using as little jargon as possible, \n",
    "the expression \"simple effect\" need not appear in the description. \n",
    "An example is as follows:\n",
    "\n",
    "The effect of Outcome differed depending on the subject's self-esteem. \n",
    "The difference between the attribution to self following success and the attribution to \n",
    "self following failure was larger for high-self-esteem subjects (mean difference = 2.50) \n",
    "than for low-self-esteem subjects (mean difference = -2.33).\n",
    "\n",
    "No further analyses are helpful in understanding the interaction since the interaction \n",
    "means only that the simple effects differ. \n",
    "The interaction's significance indicates that the simple effects differ from each other, \n",
    "but provides no information about whether they differ from zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Effect Tests\n",
    "\n",
    "It is not necessary to know whether the simple effects differ from zero in order to understand \n",
    "an interaction because the question of whether simple effects differ from zero has nothing to \n",
    "do with interaction except that if they are both zero there is no interaction. \n",
    "It is not uncommon to see research articles in which the authors report that they analyzed \n",
    "simple effects in order to explain the interaction. \n",
    "However, this is not a valid approach since an interaction does not depend on the analysis of the simple effects.\n",
    "\n",
    "However, there is a reason to test simple effects following a significant interaction. \n",
    "Since an interaction indicates that simple effects differ, it means that the main effects are not general. \n",
    "In the made-up example, the main effect of Outcome is not very informative, \n",
    "and the effect of outcome should be considered separately for high- and low-self-esteem subjects.\n",
    "As will be seen, the simple effects of Outcome are significant and in opposite directions: \n",
    "Success significantly increases attribution to self for high-self-esteem subjects and \n",
    "significantly lowers attribution to self for low-self-esteem subjects. \n",
    "This is a very easy result to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "How can the simple effects both be zero if they differ from each other significantly as tested by the interaction? The answer is that a non-significant simple effect does not mean that the simple effect is zero: \n",
    "The null hypothesis should not be accepted just because it is not rejected.\n",
    "\n",
    "If neither simple effect is significant, the conclusion should be that the simple effects differ, \n",
    "and that at least one of them is not zero. \n",
    "However, no conclusion should be drawn about which simple effect(s) is/are not zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another error that can be made by mistakenly accepting the null hypothesis is to conclude that \n",
    "two simple effects are different because one is significant and the other is not. \n",
    "\n",
    "Consider the results of an imaginary experiment in which the researcher hypothesized that \n",
    "addicted people would show a larger increase in brain activity following some treatment \n",
    "than would non-addicted people. \n",
    "In other words, the researcher hypothesized that addiction status and treatment would interact. \n",
    "The results shown in Figure 2 are very much in line with the hypothesis. \n",
    "However, the test of the interaction resulted in a probability value of 0.08, \n",
    "a value not quite low enough to be significant at the conventional 0.05 level. \n",
    "The proper conclusion is that the experiment supports the researcher's hypothesis, \n",
    "but not strongly enough to allow a confident conclusion.\n",
    "\n",
    "<img src=\"../images/figure2_2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the researcher was not satisfied with such a weak conclusion and went on to test the simple effects. \n",
    "It turned out that the effect of Treatment was significant for the Addicted group (p = 0.02) \n",
    "but not significant for the Non-Addicted group (p = 0.09). \n",
    "The researcher then went on to conclude that since there is an effect of Treatment for the Addicted group \n",
    "but not for the Non-Addicted group, the hypothesis of a greater effect for the former than for the latter group is demonstrated. \n",
    "This is faulty logic, however, since it is based on accepting the null hypothesis that the simple \n",
    "effect of Treatment is zero for the Non-Addicted group just because it is not significant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Components of Interaction \n",
    "\n",
    "Figure 3 shows the results of an imaginary experiment on diet and weight loss. \n",
    "A control group and two diets were used for both overweight teens and overweight adults.\n",
    "\n",
    "<img src=\"../images/figure3_2.PNG\">\n",
    "\n",
    "The difference between Diet A and the Control diet was essentially the same for teens and adults, \n",
    "whereas the difference between Diet B and Diet A was much larger for the teens than it was for the adults. \n",
    "Over one portion of the graph the lines are parallel whereas over another portion they are not. \n",
    "It is possible to test these portions or components of interactions using the method of specific \n",
    "comparisons discussed previously. \n",
    "The test of the difference between Teens and Adults on the difference between Diets A and B \n",
    "could be tested with the coefficients shown in Table 4. \n",
    "Naturally, the same considerations regarding multiple comparisons and orthogonal comparisons \n",
    "that apply to other comparisons among means also apply to comparisons involving components of interactions.\n",
    "\n",
    "<img src=\"../images/table4_2.PNG\">\n",
    "\n",
    "---\n",
    "Now let's look a code example:\n",
    "Again, constructing data with measurements of three sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "site1 <- c(34,25,27,31,26,34,21)\n",
    "site2 <- c(33,35,31,31,42,33,22)\n",
    "site3 <- c(17,30,30,26,32,28,26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data <- data.frame(\n",
    "       Y=c(site1, site2, site3),\n",
    "       Site =factor(rep(c(\"site1\", \"site2\", \"site3\"), times=c(length(site1), length(site2), length(site3))))\n",
    "       )\n",
    "str(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(interaction.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Two-way Interaction Plot \n",
    "\n",
    "interaction.plot(site1, site2, site3, type=\"b\", col=c(1:3), \n",
    "                 leg.bty=\"o\", leg.bg=\"beige\", lwd=2, pch=c(18,24,22),\n",
    "                 xlab=\"Site 1\",\n",
    "                 ylab=\"Site 3\", \n",
    "                 main=\"Interaction Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot he means using using the `plotmeans` from the `gplots` library.\n",
    "Please review the documentation from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Means with Error Bars\n",
    "library(gplots)\n",
    "help(plotmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotmeans(site1~site3,xlab=\"Site 1\",\n",
    "  ylab=\"Site 2\", main=\"Mean Plot\\nwith 95% CI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "This has been a whirlwind discussion of ANOVA techniques and discussions of interactions.\n",
    "Please keep in mind that you may need to revisit this lab in the future to give the material a second pass.\n",
    "\n",
    "# Save your notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
