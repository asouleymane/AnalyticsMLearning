{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic regression is also referred to as logit regression. \n",
    "It is a regression model where the dependent variable is categorical. \n",
    "The dependent variable is binary, where it can take only two values, such as pass/fail, win/lose, healthy/sick etc. \n",
    "Dependent variables with more than two categories are referred to as multinomial logistic regression.\n",
    "\n",
    "Logistic regression is a special case of the generalized linear model and is analogous to linear regression. \n",
    "It has the following assumptions between dependent ($y$) and independent variables($x_1,x_2,..,x_n$). \n",
    "\n",
    "* The conditional distribution $y\\ |\\ x$ is a Bernoulli distribution rather than a Gaussian distribution for linear regression, because the dependent variable is binary. \n",
    "\n",
    "* The predicted values are restricted to (0,1) because logistic regression predicts the probability of particular outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "\n",
    "The predictors can be continuous or categorical or a mix of both types. \n",
    "We will work with framingham dataset in this notebook. \n",
    "In this dataset we will be predicting the 10 year coronary heart disease (CHD), \n",
    "which is introduced as a Framingham risk score in one of the influential research papers in 1998. \n",
    "The dependent variable is modeled as the binary variable 1 and represents presence risk of CHD, while 0 represents absence of risk of CHD in 10 years. \n",
    "This is by its nature a categorical variable. \n",
    "It only takes on two possible values. We have seen linear regression as a way of predicting continuous outcomes. \n",
    "We can utilize linear regression to predict risk of CHD here, but then we have to round the outcome to 0 or 1. Instead we will see how we can use logistic regression, which is an extension of linear regression, in situations where the dependent variable is categorical. \n",
    "In this case it's 0 or 1. Logistic regression predicts the probability of the outcome variable being true.\n",
    "    \n",
    "Before building the model we must identify the independent variables we have to use. \n",
    "When predicting the disease we want to know the variables which are risk factors which increase the chance of disease. \n",
    "Some of the risk factors in the dataset include demographic information like male, age, education(school-1, high school/GED -2, some college/vocational - 3, college - 4) etc. \n",
    "Behavioral factors like \"current smoker\" and \"cigsPerDay\" are included. \n",
    "The rest of the possible predictors are all medical history risk factors. \n",
    "\n",
    "Let's build the model using the risk factors in the data. \n",
    "We will predict whether or not a patient experienced CHD within 10 years of first examination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Logistic_Function\"></a>\n",
    "\n",
    "`TenYearCHD` is the dependent variable ($y$). We should predict $P(y=1)$. Then $P(y=0)=1-P(y=1)$. \n",
    "\n",
    "### Logistic Function \n",
    "\n",
    "The **sigmoid function** used in logistic regression outputs the conditional probabilities of the prediction, \n",
    "the class probabilities. \n",
    "It works based on \"odds ratio\" $\\frac{p}{1 - p}$, \n",
    "which describes the ratio between the probability that a certain positive event occurs and the probability that it doesn't occur. \n",
    "Here positive refers to the \"event that we want to predict\" that is $p(y=1 | x)$. \n",
    "If you understand from the image below, the more likely that the positive event occurs, \n",
    "the larger the odds' ratio will be.\n",
    "\n",
    "<img src=\"../images/odds.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we take the natural log of this odds' ratio, logit function, we get the following\n",
    "\n",
    "$$logit(\\ p(y=1\\ |\\ x)\\ ) = log\\bigg(\\frac{p}{1-p}\\bigg) = log(p)-log(1-p) = β_0 + β_1.{x_1} + ... + β_k.{x_k}$$\n",
    "\n",
    "We don't have to predict the right part of the equation above, \n",
    "since p(y=1|x) is what we are really interested in.\n",
    "So, taking an inverse of this logit function, we get the logistic sigmoid shown below. \n",
    "We use this function to make predictions.\n",
    "\n",
    "$$ logit^{-1}(P(y=1\\ |\\ x)) = \\frac{1}{1+e^{-(β_0 + β_1.{x_1} + β_2.{x_2} + ... + β_k.{x_k})}}$$\n",
    "\n",
    "The equation looks like a complicated non linear equation but it's the familiar linear regression equation $β_0 + β_1.{x_1} + β_2.{x_2} + ... + β_k.{x_k}$ in this logistic response function. \n",
    "This function is used to produce a number between 0 and 1. \n",
    "\n",
    "<img src=\"../images/logistic_response_function.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The plot above shows the logistic response function for different values of the linear regression piece. \n",
    "The logistic response function always takes values between 0 and 1 which makes sense because it's probability. \n",
    "A positive coefficient for the variables increases the linear regression piece $β_0 + β_1.{x_1} + β_2.{x_2} + ... + β_k.{x_k}$  which increases the probability that y=1 or the probability of risk of CHD. \n",
    "On the other hand a negative coefficient for the variables decreases the linear regression piece which in turn decreases the probability of y=1 or decreases the probability of risk of CHD. \n",
    "The coefficients, or betas, are selected to predict a high probability for the risk of CHD and to predict a low probability no risk of CHD.\n",
    "\n",
    "Another way to think about logistic response function is in terms of odds. The odds is the probability of 1 divided by probability of 0. Odds are greater than 1 if y=1 is more likely. Odds are less than 1 if y=0 is more likely. \n",
    "\n",
    "$$Odds = \\frac{P(y=1)}{P(y=0)}$$\n",
    "\n",
    "Odds > 1, if y=1 is more likely\n",
    "\n",
    "Odds < 1, if y=0 is more likely\n",
    "\n",
    "Odds =1 , if both outcomes are equally likely.\n",
    "\n",
    "If you substitute the logistic response function for the probabilities in the odds equation you will see that the odds are equal to e raised to the power of the linear regression equation, as shown below.\n",
    "\n",
    "$$Odds = e^{(β_0 + β_1.{x_1} + β_2.{x_2} + ... + β_k.{x_k})}$$ \n",
    "\n",
    "By taking the log of both sides $log (Odds) = (β_0 + β_1.{x_1} + β_2.{x_2} + ... + β_k.{x_k})$ the log (Odds) or **logit** looks exactly like the linear regression equation. This helps us understand how coefficients affect our prediction of the probability. A positive beta value increases the **Logit** which in turn increases the odds of 1. A negative beta value decreases the **Logit** which in turn decreases the odds of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framingham_data = read.csv(\"/dsa/data/all_datasets/framingham/framingham.csv\")\n",
    "head(framingham_data)\n",
    "framingham_data = framingham_data[complete.cases(framingham_data),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(framingham_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(framingham_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use all predictors to determine if the patient developed CHD in next 10 years. Split the data into training and testing sets. We will evaluate the predictive capability of our model on test dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try building models with different subsets of independent variables to see what the best model is that you can find. TenYearCHD, is the dependent variable and is equal to 1 if the person has risk of CHD and equal to 0 if the person had no risk of CHD. Let's see how many people had risk of CHD and how many didn't by using the table function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(framingham_data$TenYearCHD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3101/3658"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 557 out of the 3658 patients in the data set had risk of CHD, or 1, and 3101 patients had no risk of CHD, or those labeled with 0. Before building a predictive model, let's consider using a simple baseline method. In [linear_and_multiple_regression lab](Linear_and_Multiple_Regression.ipynb#R-squared), we computed the R-squared for linear regression, we compared our predictions to the baseline method of predicting the average distance to stop for all data points. In a classification problem, a standard baseline method is to just predict the most frequent outcome for all observations. Since no risk is more common than risk of CHD, in this case, we would predict that all of them have not shown any risk of CHD. If we did this, we would get 3101 out of the 3658 observations correct, or have an accuracy of about 85%. So our baseline model has an accuracy of 85%. This is what we'll try to beat with our logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data set randomly into a training set and testing set so that we'll have a test set to measure our out-of-sample accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# install.packages(\"caTools\",repo=\"https://cran.cnr.berkeley.edu/\")\n",
    "library(caTools)\n",
    "set.seed(1000) # set.seed() will help us to reproduce the results.\n",
    "split = sample.split(framingham_data$TenYearCHD, SplitRatio=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample.split` randomly splits the dataset based on the outcome variable while keeping the SplitRatio in mind.\n",
    "It also makes sure that the outcome variable is well-balanced in each piece. \n",
    "We have seen that about 85% of people don't have risk of CHD. \n",
    "This function makes sure that in the training set, 85% of people don't have risk of CHD and in the testing set 85% of people don't have risk of CHD. So, the test set is representative of training set.\n",
    "\n",
    "The `SplitRatio` tells how much percentage of data we want in the training set. \n",
    "When there are more data we can afford to put less data in the training set and more in testing. \n",
    "This will increase our confidence on the model, especially if it performs better on testing data. \n",
    "Normally, you would want to put 50% to 80% of the data in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference: ** [set.seed()](http://rfunction.com/archives/62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split up the data using subset(). split==TRUE will give 70% of data as we mentioned above using SplitRatio parameter. \n",
    "train_data  = subset(framingham_data, split==TRUE)\n",
    "\n",
    "# Test data will have the remaining 30% of data\n",
    "test_data  = subset(framingham_data, split==FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now let's create our training and testing sets using the subset function. \n",
    "We'll call our training set train_data and use the subset function to take a subset of `framingham_data` and only taking the observations for which spit is equal to TRUE. \n",
    "We'll call our testing set test_data and, again, use the subset function to take the observations of framingham_data, but this time those for which split is equal to FALSE.\n",
    "\n",
    "We can build a logistic regression model using all the independent variables present in the dataset. \n",
    "We use the \"glm\" function for \"generalized linear model\" to build our logistic regression model. \n",
    "We start with the dependent variable, and then the tilde sign, and then the independent variables. \n",
    "Since we want to use all independent variables, \n",
    "they can be included using a dot(.) as shown in below code cell. \n",
    "We then give the name of the data set we want to use to build the model, in this case, train_data. \n",
    "For a logistic regression model, we need one last argument, which is family=binomial. \n",
    "This tells the glm function to build a logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "framingham_log = glm(TenYearCHD ~., \n",
    "                     data=train_data,family=binomial) \n",
    "                # family=binomial tell glm() to build  \n",
    "                # a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the model using the summary function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(framingham_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(family) # Run this cell if you want to learn more about family parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference: **[glm()](http://www.statmethods.net/advstats/glm.html)\n",
    "\n",
    "The output looks similar to that of a linear regression model.\n",
    "What we want to focus on is the coefficients table. \n",
    "This gives the estimate values for the coefficients, or the betas, for our logistic regression model. \n",
    "According to the p-value variables age, male, sysBP, cigsPerDay, glucose and totChol are all significant variables in the model. \n",
    "All this variables have a positive coefficient which means higher values in these variables contribute higher risk in tenYearCHD. Some of the variables have negative coefficients. \n",
    "One more important thing to look at in the output is the AIC value. \n",
    "This is a measure of the quality of the model like Adjusted R-squared which accounts for the number of variables used compared to the number of observations.\n",
    "\n",
    "Unfortunately, it can only be compared between models on the same data set. \n",
    "But it provides a means for model selection. \n",
    "The preferred model is the one with the minimum AIC. \n",
    "Now, let's make predictions in the training set. \n",
    "We'll call them predictTest and use the predict function to make predictions using the model framingham_log, \n",
    "and we'll give a second argument, which is type=\"response\". \n",
    "This tells the predict function to give us probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "predictTest = predict(framingham_log, type=\"response\", newdata=test_data) # Type='response' gives us probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the statistical summary of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(predictTest)\n",
    "# Let's do a summary on our predictions. Since the predict function has generated probabilities as output you should see values are \n",
    "# lying between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome of logistic regression function is a probability. \n",
    "We want to make a binary prediction if the subject had risk of CHD or not. We can do this using a threshold value t. \n",
    "\n",
    "If P (risk of CHD = 1) >= t, predict risk of CHD\n",
    "If P (risk of CHD = 1) < t, predict no risk of CHD\n",
    "\n",
    "So, the question is what value should be picked for `t`. \n",
    "In this example if t is large, it rarely predicts risk of CHD but there is actually a risk of CHD. \n",
    "People who have the risk of CHD go undetected.\n",
    "There is a chance of making more errors. \n",
    "\n",
    "On the other hand if t is small, subjects are identified as risk prone of CHD, which is not always true. \n",
    "When you have a preference over the error there will be an influence on the t value. \n",
    "So, with no preference between errors select t=0.5. \n",
    "It predicts the more likely outcome.  We can decide on a threshold value t using a confusion matrix. \n",
    "Rows are labelled with actual outcome and columns are labelled with predicted outcome. \n",
    "So, the '**True Negatives(TN)**' are the observations which we predicted as no risk of CHD and there is actually no risk of CHD.\n",
    "'**True Positives(TP)**' are the observations which we predicted as risk of CHD and there is actually risk of CHD.\n",
    "'**False Positives(FP)**' are the observations which we predicted as risk of CHD but there is no risk of CHD.\n",
    "'**False Negatives(FN)**' are the observations which we predicted as no risk of CHD but there is a risk of CHD. \n",
    "\n",
    "|        |  Predicted=0      | Predicted=1       |\n",
    "|--------|-------------------|-------------------|\n",
    "|Actual=0|True Negatives(TN) |False Positives(FP)|\n",
    "|Actual=1|False Negatives(FN)|True Positives(TP) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute two outcome measures that help us determine what type of errors we are making. \n",
    "They are called **Sensitivity** and **Specificity**. \n",
    "\n",
    "Sensitivity = TP/(TP+FN), \n",
    "this is often called the true positive rate.\n",
    "\n",
    "Specificity = TN(TN+FP), \n",
    "this is called the true negative rate. \n",
    "A model with a higher threshold will have a lower sensitivity and a higher specificity. \n",
    "A model with a lower threshold will have a higher sensitivity and a lower specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a confusion matrix using a threshold of 0.5\n",
    "table(test_data$TenYearCHD, predictTest>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity = TP/(TP+FN) = 16/(16+151) = 0.095\n",
    "\n",
    "Specificity = TN/(TN+FP) = 926/(926+4) = 99.56\n",
    "\n",
    "With a threshold of 0.5 we predict an outcome of 1 in the true column of the above output very rarely. This means our model rarely predicts a Ten Year CHD risk above 50%. Decrease the threshold value to 0.3 and build the confusion matrix again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a confusion matrix using a threshold of 0.3\n",
    "table(test_data$TenYearCHD, predictTest>0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity = 43/(124+43) = 0.257\n",
    "\n",
    "Specificity = 840/(840+90) = 0.90\n",
    "\n",
    "As you can see from the above results, as you decrease the threshold value sensitivity will increase and specificity will decrease. It works opposite way if you increase the threshold value. The sensitivity decreases and specificity increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the accuracy of the model with a threshold value of 0.5. It's the sum of the cases we predicted correctly divided by all the observations in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(test_data$TenYearCHD, predictTest>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TP+TN) / number of observations in the dataset.\n",
    "(16+926)/(926+4+151+16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The accuracy of our model is about 86%. We need to compare this with a simple baseline model. The more frequent outcome in this method is zero so it will always predicts a zero or no CHD. The baseline model will have the accuracy  calculated below... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerator will have outcomes which are predicted as 0 divided by total number of observations.\n",
    "(926+4)/(926+4+151+16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the baseline model has an accuracy of 85%. Our model barely beats the baseline model but do we have a valuable model, which we achieved by varying the threshold. We still have to compute an AUC value... \n",
    "\n",
    "**Reference: ** [AUC](https://www.r-bloggers.com/illustrated-guide-to-roc-and-auc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"ROCR\",repo=\"https://cran.cnr.berkeley.edu/\")\n",
    "library(ROCR)\n",
    "# Use predict function of ROCR package to make the predictions\n",
    "ROCR_predictions = prediction(predictTest, test_data$TenYearCHD)\n",
    "as.numeric(performance(ROCR_predictions,\"auc\")@y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above value is the AUC value of testing set. \n",
    "We have an AUC of about 72% on the test set, which means the model can differentiate between low risk and high risk patients pretty well. \n",
    "We were able to build a logistic regression model with few interesting properties. \n",
    "It rarely predicted 10 year CHD risk above 50%. So, the accuracy of the model is barely over the baseline model. \n",
    "However, the model could deferentiate between low risk patients and high risk patients pretty well. \n",
    "Some of the significant variables like cigsPerDay, Cholestral, and Systolic Blood Pressure suggest interventions to prevent CHD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
