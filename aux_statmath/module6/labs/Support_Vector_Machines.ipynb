{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Support Vector Classifier lab discussed how support vector machines are used to classify data using linear boundaries.  \n",
    "The dependent variable in IRIS data is scattered every where, \n",
    "making it hard to create a linear boundary for classifying the observations. \n",
    "Below we will fit a SVM model with a polynomial kernal to classify the observations into classes \n",
    " * Setosa, \n",
    " * Virginica and \n",
    " * Versicolor.\n",
    "\n",
    "### Load R Library with Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(\"e1071\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(iris,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach the iris data in memory so you can reference it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attach(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a model using the \"svm\" function using a linear kernal first and evaluate its performance.\n",
    "\n",
    "For now we will limit ourself to the using just two features:\n",
    " * Sepal.Length\n",
    " * Sepal.Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(caTools)\n",
    "set.seed(1000) # set.seed() will help us to reproduce the results.\n",
    "split = sample.split(iris$Species, SplitRatio=0.66)\n",
    "\n",
    "train_data  = subset(iris, split==TRUE)\n",
    "\n",
    "# Test data will have the rest 30% of data\n",
    "test_data  = subset(iris, split==FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using Sepal.Length and Sepal.Width as the predictors. Use a linear kernal to fit the model.\n",
    "svm.model <- svm(Species ~ Sepal.Length + Sepal.Width, data = train_data, kernel = \"linear\")\n",
    "\n",
    "# Plot the Species and show the support vectors on graph. \n",
    "# the + signs are support vectors\n",
    "plot(iris$Sepal.Length, iris$Sepal.Width, col = as.integer(iris[, 5]), # color the points based on species \n",
    "     pch = c(\"o\",\"+\")[1:150 %in% svm.model$index + 1], \n",
    "       # Mark the support vectors with a `+` sign and test with a `o` sign\n",
    "       # \"1:150 %in% svm.model$index\" will generate a vector of size 150\n",
    "       # with TRUE and FALSE values. A TRUE is assigned if the value is a \n",
    "       # support vector. Addimg one to the vector will give values 1 and 2 \n",
    "       # instead of TRUE(1) and FALSE(0). Every 1 in the vector is displayed\n",
    "       # as o and 2 is displayed as +. \n",
    "     cex = 2, \n",
    "     xlab = \"Sepal length\", ylab = \"Sepal width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Species by splitting the feature space into three different regions according to species class\n",
    "plot(svm.model, iris, Sepal.Width ~ Sepal.Length, # Plot the model predictions with sepal.width on y-axis and sepal.length\n",
    "                                                  # on x-axis\n",
    "     slice = list(sepal.width = 1, sepal.length = 2)) # a list of named numeric values for the dimensions held constant \n",
    "                                                      # slice is needed if more than two variables are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions of species using the svm model built\n",
    "svm.pred  <- predict(svm.model, test_data[,-5]) \n",
    "\n",
    "# Build a confusion matrix for the predictions made against the original classes of flowers\n",
    "library(caret)\n",
    "confusionMatrix(svm.pred, test_data[,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The svm model did not do a great job with a linear kernal. The accuracy of the model is 74.5\n",
    "         \n",
    "         (17+10+11)/51  --- number of TRUE predictions/total observations \n",
    "         \n",
    "**Reference: ** [Confusion matrix function and its results](http://rpubs.com/prcuny/161764)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model using a Non-Linear Kernal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using a polynomial kernal and Sepal.Length, Sepal.Width as predictor variables.\n",
    "svm.model <- svm(Species ~ Sepal.Length + Sepal.Width, data = train_data, kernel = 'polynomial', degree=8, coef0=1)\n",
    "                      # For polynomial kernels we use the parameter degree to adjust the polynomial order. \n",
    "                      # For radial kernels we use the gamma parameter to adjust the y value.\n",
    "                      # Independent term in kernel function. It is only significant in ‘polynomial’ \n",
    "                      # and ‘sigmoid’ kernals\n",
    "                  \n",
    "plot(svm.model, iris, Sepal.Width ~ Sepal.Length,      # Plot the predictions\n",
    "     slice = list(Sepal.Width = 1, Sepal.Length = 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.pred  <- predict(svm.model, test_data[,-5]) \n",
    "confusionMatrix(svm.pred, test_data[,5]) # show the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no improvement in the accuracy of the model even after using a polynomial of degree 8.  \n",
    "We previously only used just two attributes for making predictions. \n",
    "We will now use all independent variables for building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm.model <- svm(Species ~ ., data = train_data, kernel = 'polynomial', degree=8, coef0=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.pred  <- predict(svm.model, test_data[,-5]) \n",
    "confusionMatrix(svm.pred, test_data[,5]) # show the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using all variables as predictors we got over 90% accuracy in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radial Kernal\n",
    "\n",
    "Now we will investigate using a radial kernel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm.model <- svm(Species ~., data=train_data, kernel='radial', gamma=1, cost=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat <- predict(svm.model, test_data)\n",
    "confusionMatrix(yhat, test_data[,'Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune the model\n",
    "\n",
    "Tuning SVM to find the best cost and gamma.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tune <- tune(svm, train.x=train_data[,-5], train.y=train_data[,5], \n",
    "              kernel=\"radial\", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))\n",
    "\n",
    "print(svm_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you find the best cost and gamma, you can create AVM model again and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_after_tune <- svm(Species ~ ., data=train_data, kernel=\"radial\", cost=1, gamma=0.5)\n",
    "summary(svm_model_after_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat <- predict(svm_model_after_tune, test_data)\n",
    "confusionMatrix(yhat, test_data[,'Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now gotten 100% accurate results after tuning the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Reference:** \n",
    "  * [SVM tutorial 1](http://www.di.fc.ul.pt/~jpn/r/svm/svm.html#non-linearly-separable-data) \n",
    "  * [SVM tutorial 2](https://rpubs.com/ryankelly/svm)\n",
    "  \n",
    "# Save your Notebooks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
