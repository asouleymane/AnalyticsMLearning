{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression model discussed in module 5 assumes that the response variable $Y$ is \n",
    "quantitative (continuous numerical value). \n",
    "However, what happens if the response variable is qualitative (categorical). \n",
    "For example, eye color is qualitative taking values blue, brown, green, etc. \n",
    "The process of predicting qualitative responses is known as **classification**, as you have been learning.\n",
    "\n",
    "Often the methods used for classification first predict the probability of each of the \n",
    "categories of a qualitative variable, as the basis for making the classification. \n",
    "In this sense, they also behave like regression methods.\n",
    "\n",
    "An example classification problem could be an online banking service that must be able \n",
    "to determine whether or not a transaction being performed on the site is fraudulent, \n",
    "on the basis of the user’s IP address, past transaction history etc. \n",
    "In this notebook we will continue our discussion on Logistic Regression. \n",
    "We will refer to both our `Heart Disease` and then, primarily, the `Default` data set. \n",
    "For the `Default` data, we are interested in predicting whether an individual will \n",
    "default on his or her credit card payment, on the basis of annual income and monthly credit card balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why not Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is stated Linear Regression is not an ideal choice predicting a categorical variable. \n",
    "Suppose that we are trying to predict the medical condition of a patient in the emergency room on the basis of her symptoms. \n",
    "There are three possible diagnoses: stroke, drug overdose, and epileptic seizure. \n",
    "We could consider encoding these values as a quantitative response variable, $Y$ , as follows:\n",
    "\n",
    "$$Y=\\begin{gather*}\n",
    "\\begin{cases}\n",
    "1,\\ if\\ Stroke;\\\\\n",
    "2,\\ if\\ Drug\\ Overdose;\\\\\n",
    "3,\\ if\\ Epileptic\\ Seizure.\\\\\n",
    "\\end{cases}\n",
    "\\end{gather*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this coding, least squares could be used to fit a linear regression model to predict Y \n",
    "on the basis of a set of predictors $X_1, . . .,X_p$. \n",
    "Unfortunately, this coding implies an ordering on the outcomes, \n",
    "putting drug overdose in between stroke and epileptic seizure, \n",
    "and insisting that the difference between stroke and drug overdose is the same \n",
    "as the difference between drug overdose and epileptic seizure. \n",
    "In practice there is no particular reason that this needs to be the case. \n",
    "For instance, one could choose an equally reasonable coding,\n",
    "\n",
    "$$Y=\\begin{gather*}\n",
    "\\begin{cases}\n",
    "1,\\ if\\ Epileptic\\ Seizure.\\\\\n",
    "2,\\ if\\ Stroke;\\\\\n",
    "3,\\ if\\ Drug\\ Overdose;\\\\\n",
    "\\end{cases}\n",
    "\\end{gather*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would imply a totally different relationship among the three conditions. \n",
    "\n",
    "Each of these codings would produce fundamentally different linear models that would \n",
    "ultimately lead to different sets of predictions on test observations. \n",
    "In general there is no natural way to convert a qualitative response variable with more than two \n",
    "levels into a quantitative response that is ready for linear regression.\n",
    "\n",
    "If there are only two possibilities for the patient’s medical condition: stroke and drug overdose. \n",
    "We could then potentially use the dummy variable approach to code the response as follows:\n",
    "\n",
    "$$Y=\\begin{gather*}\n",
    "\\begin{cases}\n",
    "1,\\ if\\ Stroke;\\\\\n",
    "2,\\ if\\ Drug\\ Overdose;\\\\\n",
    "\\end{cases}\n",
    "\\end{gather*}$$\n",
    "\n",
    "\n",
    "We could then fit a linear regression to this binary response, and predict drug overdose \n",
    "if $\\hat{Y}$ >0.5 and stroke otherwise. \n",
    "In the binary case it is not hard to show that even if we flip the above coding, \n",
    "linear regression will produce the same final predictions. \n",
    "For a binary response with a 0/1 coding as above, regression by least squares does make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is a pictorial illustration of why linear regression is a bad choice for categorical variables. \n",
    "\n",
    "<img src=\"../images/linear_vs_logistic_regression.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The picture on the left is the estimated probability of using linear regression. \n",
    "Some estimated probabilities are negative! \n",
    "The orange ticks indicate the 0/1 values coded for default (No or Yes). \n",
    "The right plot is the predicted probabilities of default using logistic regression. \n",
    "All probabilities lie between 0 and 1.\n",
    "\n",
    "Considering the data set, the response will be either Yes or No. \n",
    "Rather than modeling this response Y directly, \n",
    "logistic regression models the probability that Y belongs to a particular category. \n",
    "\n",
    "For example, the probability of **default given balance** can be written as\n",
    "\n",
    "$$P(default = Yes\\ |\\ balance).$$\n",
    "\n",
    "The values of $P(default = Yes\\ |\\ balance)$, which we abbreviate `P(default|balance)`, will range between 0 and 1. \n",
    "Then for any given value of balance, a prediction can be made for default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model\n",
    "\n",
    "The relationship we are interested in the above plot is between $P(Y = 1\\ |\\ X)$ \n",
    "(call this a function of X, $p(x)$) and X (predict Y=1 for a given value of X). \n",
    "The problem in using the linear regression equation $p(X) = \\beta_0$ + $\\beta_1 X$ \n",
    "is for balances close to zero we predict a negative probability of _default_. \n",
    "If we were to predict for very large balances, we would get values bigger than 1. \n",
    "The predictions are not sensible, since true probability must fall between 0 and 1. \n",
    "This problem is not unique to the credit default data. \n",
    "Any time a straight line is fit to a binary response that is coded as 0 or 1, \n",
    "in principle we can always predict p (X) < 0 for some values of X and p (X) > 1 \n",
    "for others (unless the range of X is limited).\n",
    "\n",
    "To avoid this problem, we must model $p(X)$ using a function that gives outputs between 0 and 1 for all posible values of X. \n",
    "In logistic regression, we use the logistic function shown below \n",
    "\n",
    "$$p(X) = \\frac{e^{\\beta_0+\\beta_1X}}{1 + e^{\\beta_0+\\beta_1X}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit the above model, we use a method called Maximum Likelihood. \n",
    "After manipulating the above equation a little bit we find that \n",
    "\n",
    "$$\\frac{p(X)}{1 − p(X)} = e^{\\beta_0+\\beta_1X}$$\n",
    "\n",
    "The logistic function above will always produce an S-shaped curve as shown in right hand side plot, \n",
    "and so regardless of the value of X, we will obtain a sensible prediction. \n",
    "For low balances we now predict the probability of default as close to, \n",
    "but never below, zero. \n",
    "Likewise, for high balances we predict a default probability close to, \n",
    "but never above, one. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantity $p(X)/[1−p(X)]$ is called the odds, and can take on any value between 0 and ∞. \n",
    "Values of the odds close to 0 and ∞ indicate very low and very high probabilities of default in our example, respectively. \n",
    "For example, on average 1 in 5 people with an odds of 1/4 will default, \n",
    "since p(X) = 0.2 implies an odds of $\\frac{0.2}{1−0.2} = 1/4$. \n",
    "Likewise on average nine out of every ten people with an odds of 9 will default, \n",
    "since p (X) = 0.9 implies an odds of $\\frac{0.9}{1−0.9} = 9$.\n",
    "\n",
    "By taking the logarithm of both sides of the above equation, we arrive at \n",
    "\n",
    "$$log\\bigg(\\frac{p(X)}{1 − p(X)}\\bigg) = \\beta_0 + \\beta_1X$$\n",
    "\n",
    "The left-hand side is called the log-odds or logit. \n",
    "In a linear regression model, $\\beta_1$ gives the average change in Y associated with a one-unit increase in X. \n",
    "In contrast, in a logistic regression model, increasing X by one unit changes the log odds by $\\beta_1$, \n",
    "or equivalently it multiplies the odds by ${e^{\\beta_1}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Regression Coefficients\n",
    "\n",
    "Maximum likelihood is used to estimate coefficients. \n",
    "The basic intuition behind using maximum likelihood to fit a logistic regression model is as follows: \n",
    "We seek estimates for $\\beta_0$ and $\\beta_1$ such that the predicted probability $\\hat{p}(x_i)$ \n",
    "of _default_ for each individual, corresponds as closely as possible to the individual’s observed default status. \n",
    "In other words, we try to find $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ such that \n",
    "plugging these estimates into the model for p (X), i.e.\n",
    "\n",
    "$$p(X) = \\frac{e^{\\beta_0+\\beta_1X}}{1 + e^{\\beta_0+\\beta_1X}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yields a number close to one for all individuals who defaulted, \n",
    "and a number close to zero for all individuals who did not. \n",
    "The estimates $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ are chosen to maximize this likelihood function.\n",
    "\n",
    "The table below shows the coefficient estimates and related information that result from fitting a \n",
    "logistic regression model on the Default data in order to predict the probability of `default=Yes` using balance.\n",
    "\n",
    "|          |  Coefficient Std.| error   |Z-statistic |P-value  |\n",
    "|----------|------------------|---------|------------|---------|          \n",
    "|Intercept |−10.6513          |  0.3612 |−29.5       |  <0.0001|\n",
    "|balance   |0.0055            |  0.0002 | 24.9       |  <0.0001|\n",
    "\n",
    "We see that $\\hat{\\beta_1} = 0.0055$ this indicates that an increase in balance is associated \n",
    "with an increase in the probability of default. \n",
    "To be precise, a one unit increase in balance is associated with an increase in the log odds \n",
    "of default by 0.0055 units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "\n",
    "Once the coefficients have been estimated, \n",
    "you compute the probability of default for any given credit card balance. \n",
    "For example, using the coefficient estimates given in the above table, \n",
    "we predict that the _default_ probability for an individual with a balance of $1,000 is \n",
    "\n",
    "$$p(X) = \\frac{e^{\\beta_0+\\beta_1X}}{1 + e^{\\beta_0+\\beta_1X}} = \\frac{e^{-10.6513+0.0055*1000}}{1 + e^{-10.6513+0.0055*1000}} = 0.00576$$\n",
    "\n",
    "which is below $1%$. In contrast, the predicted probability of default for an individual with \n",
    "a balance of $2,000 is much higher, and equals 0.586 or 58.6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use qualitative predictors with the logistic regression model using the dummy variable approach. \n",
    "As an example, the Default data set contains the qualitative variable student. \n",
    "To fit the model we simply create a dummy variable that takes on a value of 1 for students and 0 for non-students. The logistic regression model that results from predicting probability of default from student status can be seen below...\n",
    "\n",
    "\n",
    "|          |  Coefficient Std.| error   |Z-statistic |P-value  |\n",
    "|----------|------------------|---------|------------|---------|          \n",
    "|Intercept |−3.5041           |  0.0707 |−49.55      |  <0.0001|\n",
    "|balance   |0.4049            |  0.1150 | 3.52       |  0.0004 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient associated with the dummy variable is positive and the associated p-value is statistically significant. \n",
    "This indicates that students tend to have higher default probabilities than non-students.\n",
    "\n",
    "$$\\hat{P}(default=Yes\\ |\\ student=Yes) =  \\frac{e^{-3.5041+0.4049*1}}{1 + e^{-3.5041+0.4049*1}} = 0.0431$$\n",
    "\n",
    "$$\\hat{P}(default=Yes\\ |\\ student=No) =  \\frac{e^{-3.5041+0.4049*0}}{1 + e^{-3.5041+0.4049*0}} = 0.0292$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider the problem of predicting a binary response using multiple predictors. By analogy with the extension from simple to multiple linear regression in module 5, we can generalize the equation for the odds as follows:\n",
    "\n",
    "$$log\\bigg(\\frac{p(X)}{1 − p(X)}\\bigg) = \\beta_0 + \\beta_1X_1 + · · · + \\beta_pX_p$$ where X = (X1, . . .,Xp) are p predictors\n",
    "\n",
    "And the logistic function equation can be written as... \n",
    "\n",
    "$$p(X) = \\frac{e^{\\beta_0+\\beta_1X_1+···+\\beta_pX_p}}{1 + e^{\\beta_0+\\beta_1X_1+···+\\beta_pX_p}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression for >2 Response Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the response variable has multiple categories like the medical condition example,\n",
    "with levels _stroke_, _drug overdose_, and _epileptic seizure_, we would like to model \n",
    "both `P (Y = stroke|X)` and P `(Y = drug overdose|X)`, \n",
    "with the remaining `P (Y = epileptic seizure|X) = 1 − P (Y = stroke|X) − P (Y = drug overdose|X)`. \n",
    "The logistic regression model discussed before has a multiple-class extensions, \n",
    "but in practice they are not used often for multiple class situations because there are \n",
    "other popular approaches for multiple-class classification, such as Linear Discriminant Analysis (LDA). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will fit a logistic regression model on Stock Market Data in ISLR package. \n",
    "This data set consists of percentage returns for the S&P 500 stock index over 1,250 days, \n",
    "from the beginning of 2001 until the end of 2005. \n",
    "For each date, the percentage returns for each of the five previous trading days, \n",
    "Lag1 through Lag5 are recorded. \n",
    "The Volume (the number of shares traded on the previous day, in billions), \n",
    "Today (the percentage return on the date in question) and \n",
    "Direction (whether the market was Up or Down on this date) are also recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"ISLR\", repo=\"https://cran.fhcrc.org/\")\n",
    "library(ISLR)\n",
    "\n",
    "# Check the names of columns present in the dataset.\n",
    "names(Smarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimensions of the data.\n",
    "dim(Smarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(Smarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Direction variable is qualitative. cor() accepts numeric values only. \n",
    "#    So exclude Direction from the input to cor function\n",
    "cor(Smarket[,-9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlations between the lag variables and today’s returns are close to zero. \n",
    "In other words, there appears to be little correlation between today’s returns and previous days’ returns. \n",
    "The only substantial correlation is between Year and Volume. \n",
    "By plotting the data we see that Volume is increasing over time. \n",
    "In other words, the average number of shares traded daily increased from 2001 to 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telling R that we are going to use Smarket dataset in this data. You can refer to columns in Smarket without referring to the\n",
    "# Smarket everytime.\n",
    "attach(Smarket)\n",
    "plot(Volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Smarket` has data spanning across years 2001 to 2005. \n",
    "We can subset the data into training and testing sets. \n",
    "We will create a vector corresponding to the observations from 2001 through 2004, holding true values;\n",
    "then false values for the year 2005.\n",
    "Then, use this vector to create two datasets of observations one with data from 2001 to 2004 and the other one containing 2005 data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The object train is a vector of 1,250 elements. The elements of the \n",
    "# vector that correspond to observations that occurred before 2005 are \n",
    "# set to TRUE as they satisfy the condition \"Year<2005\". \n",
    "# whereas those that correspond to observations in 2005 are set to FALSE. \n",
    "train = Year<2005\n",
    "\n",
    "# train is a Boolean vector, since its elements are TRUE and FALSE. \n",
    "# So, the TRUE and FALSE values corresponding to each row\n",
    "# will let you subset rows or columns of a matrix. For instance, the \n",
    "#  command Smarket[!train,] would pick out a submatrix of the\n",
    "# stock market dataset, corresponding to observations in 2005, since \n",
    "#  those are the ones for which the elements of train are \n",
    "# FALSE and `!` operator will reverse the elements of train vector.\n",
    "Smarket.2005= Smarket[!train,]\n",
    "\n",
    "# Check the dimensions of Smarket.2005\n",
    "dim(Smarket.2005)\n",
    "\n",
    "# Save the Direction values corresponding to 2005 dates.\n",
    "Direction.2005 = Direction[!train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then fit a logistic regression model using only the subset of the observations that correspond to dates before 2005, using the subset argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset argument below is providing the condition for what data to be selected from Smarket. \n",
    "# If you are not sure what's \n",
    "# happening run below table command. \n",
    "glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial, subset=train)\n",
    "\n",
    "# Predicted probabilities of the stock market for each of the days in \n",
    "# the test set that is, for the days in 2005\n",
    "glm.probs = predict(glm.fit, Smarket.2005, type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the predictors are good enough to predict the direction of the stock market. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data for years from 2001 through 2004 using train vector. Use table function to see distribution of Year values\n",
    "# in the subset.\n",
    "table(subset(Smarket,train)$Year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained the model using only the dates before 2005, \n",
    "and the fitted model is tested on data with dates in 2005. \n",
    "The predictions for 2005 are in glm.probs. \n",
    "Compare them to the actual movements of the market over that time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector glm.pred of size 252 to store the predictions. \n",
    "# Assign the value `down` initially for entire vector \n",
    "glm.pred=rep(\"Down\" ,252)\n",
    "\n",
    "# Update the predictions in glm.pred to 'up' if predicted probability is greater than 0.5\n",
    "glm.pred[glm.probs >0.5]=\" Up\"\n",
    "\n",
    "# table() function can be used to produce a confusion matrix in order to determine how many observations were correctly or \n",
    "# incorrectly classified.\n",
    "table(glm.pred, Direction.2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the names() function to find out what other pieces of information are stored in glm.fit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the coef() function in order to access just the coefficients for this fitted model\n",
    "coef(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confint(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(glm.pred==Direction.2005)\n",
    "mean(glm.pred!= Direction.2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `!=` notation means **not equal** to and so the last command computes the test set error rate. \n",
    "The test error rate is 69%, which is worse than random guessing. \n",
    "Therefore, we will remove the variables that appear not to be helpful in predicting Direction. \n",
    "Using predictors that have no relationship with the response variable tends to cause a \n",
    "deterioration in the test error rate, \n",
    "since such predictors cause an increase in variance without a corresponding decrease in bias.\n",
    "\n",
    "We will refit the logistic regression using just `Lag1` and `Lag2` which have better P-values compared to rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.fit=glm(Direction~Lag1+Lag2, data=Smarket, family=binomial, subset =train)\n",
    "glm.probs = predict(glm.fit, Smarket.2005, type=\"response\")\n",
    "\n",
    "glm.pred=rep(\"Down\", 252)\n",
    "glm.pred[glm.probs >0.5]=\"Up\"\n",
    "\n",
    "table(glm.pred, Direction.2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(glm.pred == Direction.2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "106/(106+76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look good compared to the previous model. \n",
    "56% of the daily movements have been correctly predicted. \n",
    "The confusion matrix suggests that on days when logistic regression predicts that the market will decline, \n",
    "it is only correct 50% of the time. \n",
    "However, on days when it predicts an increase in the market, it has a 58% accuracy rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
