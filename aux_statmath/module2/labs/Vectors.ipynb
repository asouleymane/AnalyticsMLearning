{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Data\n",
    "\n",
    "We have done univariate analyses in the previous module. \n",
    "All the datasets we have looked into so far were multivariate, \n",
    "but we focused on analyzing individual variables, performing basic descriptive and inferential statistics. \n",
    "Afterward, we did some bivariate analyses. \n",
    "However, what if you wanted to analyze more than two variables at once? \n",
    "In this module, focus will be on multivariate data.\n",
    "\n",
    "Multivariate data can have two or more dimensions. \n",
    "Often, more than one variable is collected in an experiment or any observation. \n",
    "When considering multivariate data, we must take into account interdependencies and correlations of data vectors.\n",
    "\n",
    "For example, in a demographic study many features such as age, sex, race, education, job, income level etc. are included in the survey. \n",
    "The datasets will have more than two quantitative variables for each row/observation.\n",
    "\n",
    "A key issue to address is that with increasingly wide data sets, \n",
    "it becomes increasingly more challenging to do visual exploration of the data. \n",
    "Visual exploration is possible when looking at a data set of 2, 3, 4 variables as shown in the lecture/videos,\n",
    "but anything beyond this range should be dealt with using numerical analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a vector?\n",
    "\n",
    "The word vector is the name that approximates the meaning of the term \"variable\". \n",
    "Data scientists often use the four following words (variable, vector, array, and distribution) interchangeably while communicating to others. \n",
    "When multiple vectors (variables) are combined and stored into a data set in R, we call it a data frame. \n",
    "\n",
    "When R stores vectors into a data frame, it assigns a role to indicate how the data will be used in subsequent statistical analyses. \n",
    "So in R data frames, for example, the \"logical,\" \"date/time,\" and \"character\" data types are assigned the role of Factor. \n",
    "The \"double\" data type are assigned the role of num and \"integers\" are assigned the role of int \n",
    "(the \"complex\" data type is assigned the role of \"cplx,\" but don't worry about that now). \n",
    "These roles correspond to statistical data types as follows: \n",
    " * Factor = nominal, \n",
    " * int = ordinal, and \n",
    " * num = interval.\n",
    "\n",
    "So, every variable or distribution or array is a vector. \n",
    "\n",
    "\n",
    "Additionally, every datum within a dataset is typically a vector of related values.\n",
    "We will cover these vectors in more detail as we proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Data\n",
    "\n",
    "Previously, we discussed measures of central tendency, variability, and spread. \n",
    "These summarize a single variable by providing important information about its distribution. \n",
    "Before discussing multivariate data, let's recap bivariate data. \n",
    "As you will recall, bivariate analysis consist of two quantitative variables. \n",
    "It is analogous to summarizing univariate (single variable) data.\n",
    "\n",
    "For illustration, consider analysis of abdominal circumference vs. gestation period. \n",
    "Let’s begin by asking if abdominal circumference varies with gestation period. \n",
    "From experience we can say it's true, but how good is the correlation? \n",
    "One way to address the question is to look at abdominal circumference against gestation period for a sample of the data. \n",
    "\n",
    "<img src=\"../images/table_data.PNG\">\n",
    "\n",
    "Going across the columns we see that, babies with higher gestation periods tend to have higher abdominal circumference than babies with lower gestation periods but this is not true in all cases. \n",
    "The data reflects our experience but the expecation is not always the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_data = read.csv(\"/dsa/data/all_datasets/abdominal circumference/ac.csv\")\n",
    "ac_data = ac_data[,2:ncol(ac_data)]\n",
    "head(ac_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "par(mfrow=c(1,2))\n",
    "hist(ac_data$gawks)\n",
    "hist(ac_data$ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the means and standard deviations of gestation period and abdominal circumference\n",
    "   \n",
    "   |gawks|ac\n",
    "----|-----|----\n",
    "mean|27.26|226.71\n",
    "sd  |8.45 |88.64\n",
    "\n",
    "\n",
    "From the first table above we can see that not all babies with a longer gestation period have a larger abdominal circumference. \n",
    "This relationship can't be seen when we separate the variables. \n",
    "We cannot answer questions based on means or standard deviation alone. \n",
    "For example, based on means alone, we can't answer what percentage of babies have an abdominal circumference greater than 300. \n",
    "We have to count across pairs to find this out. \n",
    "Another example where information is not available from the separate descriptions of gestation period and abdominal circumference is the mean gestation period of babies with certain abdominal circumferences. \n",
    "Finally, we don't know the relationship between gestation period and abdominal circumference.\n",
    "\n",
    "We can learn more by displaying the bivariate data in a graphical form that maintains the pairing as shown below. The x-axis represents the gestation period of babies and the y-axis has abdominal circumference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(ac_data$gawks,ac_data$ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two important characteristics of the data revealed from above plot. \n",
    "First, there is a strong relationship between the gestation period and abdominal circumference: \n",
    "the longer the gestation period the greater the abdominal circumference, generally speaking.\n",
    "When one variable (Y) increases with the second variable (X), we say that X and Y have a positive association. Conversely, when Y decreases as X increases, we say that they have a negative association.\n",
    "\n",
    "Notice how the points are clustered along a straight line. \n",
    "This relationship is called a linear relationship.\n",
    "\n",
    "Scatter plots that show linear relationships between variables can differ in several ways including the slope of the line about which they cluster and how tightly the points cluster about the line. \n",
    "A statistical measure of the strength of the relationship between two quantitative variables that takes these factors into account is **Pearson's Correlation** or simply as the **correlation coefficient**.\n",
    "\n",
    "Before we learn more about correlation we should look into covariance first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance\n",
    "\n",
    "The covariance of two variables x and y in a data set measures how the two are linearly related. \n",
    "It’s similar to variance, where variance tells you how a single variable varies, \n",
    "but covariance tells you how two variables vary together. \n",
    "A positive covariance would indicate a positive linear relationship between the variables, \n",
    "and a negative covariance would indicate the opposite.\n",
    "\n",
    "$$cov(X,Y) = E([X-E(X)][Y-E(Y)])$$\n",
    "\n",
    "and correlation is given as,\n",
    "\n",
    "$$cor(X,Y) = \\frac{cov(X,Y)}{sd(X)sd(Y)}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov(ac_data$gawks,ac_data$ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we need to estimate correlation?\n",
    "\n",
    "The problem with covariances is that they are hard to compare. \n",
    "For example when you calculate the covariance of a set of heights and weights, \n",
    "as expressed in meters and kilograms respectively, \n",
    "you will get a different covariance from when you do it in other unit. \n",
    "Additionally, it will be hard to tell if, for example, height and weight 'covary better' than, \n",
    "for example the length of your toes and fingers, \n",
    "simply because the 'scale' you calculate the covariance on is different.\n",
    "\n",
    "The solution to this is to 'normalize' the covariance. \n",
    "The covariance is divided by something that represents the diversity and scale in both the covariates, \n",
    "and you end up with a value  between -1 and 1, which is the correlation coefficient. \n",
    "Whatever unit your original variables were in, normalizing the covariance between -1 and 1 means that you can, to a certain degree, compare whether two variables 'correlate' more than other sets of two variables, \n",
    "simply by comparing their correlation coefficient.\n",
    "\n",
    "If the relationship between the variables is not linear, \n",
    "then the correlation coefficient does not adequately represent the strength of the relationship between the variables. \n",
    "The symbol for Pearson's correlation is $\\rho$ when it is measured in the population and \"r\" when it is measured in a sample. \n",
    "Pearson's r can range from -1 to 1. \n",
    "An r of -1 indicates a perfect negative linear relationship between variables, an r of 0 indicates no linear relationship between variables, and an r of 1 indicates a perfect positive linear relationship between variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cor(ac_data, use=\"pairwise.complete.obs\", method=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Properties of Pearson R**: \n",
    "* Pearson's correlation is symmetric in the sense that the correlation of X with Y is the same as the correlation of Y with X. You can see that in above result. \n",
    "\n",
    "* A critical property of Pearson's r is that it is unaffected by linear transformations. This means that multiplying a variable by a constant and/or adding a constant does not change the correlation of that variable with other variables. For instance, the correlation of Weight and Height does not depend on whether Height is measured in inches, feet, or even miles. Similarly, adding five points to every student's test score would not change the correlation of the test score with other variables such as GPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Compute Pearson's r\n",
    "\n",
    "There are many ways (formulas) to compute Pearson's correlation. \n",
    "Some formulas make more conceptual sense, whereas others are easier to actually compute.\n",
    "\n",
    "\n",
    "**Calculation of r**\n",
    "\n",
    "<img src=\"../images/computing_pearsons_r.PNG\">\n",
    "\n",
    "Consider we have to calculate pearsons r value for columns X and Y in above table. \n",
    "Begin by computing the mean for X and subtracting this mean from all values of X. \n",
    "The new variable is called \"x.\" \n",
    "The variable \"y\" is computed similarly. \n",
    "The variables x and y are said to be deviation scores because each score is a deviation from the mean. \n",
    "Notice that the means of x and y are both 0 (if the data is normally distributed, \n",
    "the deviation be would be almost zero). \n",
    "The same is explained in the next cell for gawks in ac_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(scipen=999)\n",
    "\n",
    "ac_data_gawks_mean = mean(ac_data$gawks)\n",
    "ac_data_gawks_dev = ac_data$gawks-ac_data_gawks_mean\n",
    "sum(ac_data_gawks_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a new column by multiplying x and y. \n",
    "\n",
    "Summing the **xy** column reveals the relationship between X and Y. Why?\n",
    "\n",
    "    If there was no relationship between X and Y, then positive values of x would be just as likely to be paired with negative values of y as with positive values. This would make negative values of xy as likely as positive values and the sum would be small. On the  other hand, consider Table 1 in which high values of X are associated with high values of Y and low values of X are associated with low values of Y. You can see that positive values of x are associated with positive values of y and negative values of x are associated with negative values of y. In all cases, the product of x and y is positive, resulting in a high total for the xy column. Finally, if there were a negative relationship then positive values of x would be associated with negative values of y and negative values of x would be associated with positive values of y. This would lead to negative values for xy.\n",
    "\n",
    "Pearson's r is designed so that the correlation between variables is the same no matter what units they are measured in.\n",
    "To achieve this property, Pearson's correlation is computed by dividing the sum of the xy column (Σxy) by the square root of the product of the sum of the $x^2$ column (Σ$x^2$) and the sum of the $y^2$ column (Σ$y^2$). \n",
    "The resulting formula is:\n",
    "\n",
    "$$r = \\frac{\\sum xy}{\\sqrt{\\sum x^2 \\sum y^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual vector compared to a scalar value\n",
    "\n",
    "A vector can be analyzed using visuals and scalar values. \n",
    "The plot below shows the distribution of gestation period values with the mean highlighted in red. \n",
    "A scalar value: 27.2669789508197 for mean would give less information against the visual of the vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x <- 0:50\n",
    "\n",
    "hist(ac_data$gawks, probability = TRUE,main=\"gestation period distribution\",xlab=\"gestation period\",ylab=\"density\",ylim = c(0, 0.05))\n",
    "# x <- min(ac_data$gawks):max(ac_data$gawks)\n",
    "y <- dnorm(x = x, mean = mean(ac_data$gawks), sd = sd(ac_data$gawks))\n",
    "lines(x = x, y = y, col = \"blue\")\n",
    "abline(v = mean(ac_data$gawks), col = \"red\", lwd =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need vectors?\n",
    "\n",
    "Nearly everything in mathematical modeling is a vector in one way or another. \n",
    "Vectors can have any number of dimensions. \n",
    "In the prior module we were looking at 1 dimensional vectors, but they can have hundreds, \n",
    "thousands, or occasionally millions of dimenions. \n",
    "Some examples of vectors are: stock indices, images, videos, audio signals, probability densities, in fact almost anything called a distribution, GPS solutions, and survey responses on scales are all vectors. \n",
    "\n",
    "One dimensional vectors look just like plain old numbers. \n",
    "They explain why real numbers have signs, i.e. directions.\n",
    "\n",
    "In most Data Science problems you have a dataset in the form of **m rows and n columns** where each row is a datum, \n",
    "point, or observation and each column is a feature or attribute.\n",
    "\n",
    "The dataset is then a `m x n` matrix and you can represent it in many different ways. \n",
    "You can approximate any point in your data as a linear combination of some vectors or as a base of a vector space. \n",
    "The choice of base depends on the problem you are trying to solve since different algorithms create different base.\n",
    "For example, algorithms such as SVD/PCA, NMF, and K-Means will create different bases.\n",
    "\n",
    "So, from the point of view of Data Science a vector space creates a representation of data from the point of view of a given base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
