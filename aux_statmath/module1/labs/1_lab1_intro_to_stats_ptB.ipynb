{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing Statistics and R, part B\n",
    "\n",
    "This is a continuation of your first lab for the Introduction to Statistical and Mathematical Foundations of Data Science course. \n",
    "You can refer to chapters 1 to 3 in [Intro to Statistics textbook](http://onlinestatbook.com/2/index.html) book for reference. \n",
    "\n",
    "\n",
    "** We now continue with the final portion of the introductory lab**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential Statistics\n",
    "\n",
    "Inferential statistic measures help us draw inferences about larger population from sample data. \n",
    "You rarely have access to full population datasets. \n",
    "\n",
    "Consider the following: \n",
    "The evidence linking cigarette smoking and lung disease is almost irrefutable. \n",
    "Based upon this information, what proportion of Americans have given up smoking? \n",
    "One way to answer this question would be to survey the entire population of the United States. \n",
    "It would be impossible from the standpoint of time and cost-effectiveness. \n",
    "Mathematicians have created methods of estimating population parameters from samples drawn from target populations that adequately represent the larger population. \n",
    "\n",
    "In inferential statistics we will be answering questions or testing hypotheses about populations based upon samples or prior data. \n",
    "Since parameters of populations are generally not available we must rely on sampling techniques to estimate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Distributions\n",
    "\n",
    "A sampling distribution is a theoretical distribution that would result if we were to take all possible samples from a given population. \n",
    "Suppose we were able to draw a representative sample using 20 individuals (N=20) from a population. \n",
    "We could then calculate what is referred to as a sampling distribution. \n",
    "We typically draw fewer samples with knowledge that there will be some error. \n",
    "This error term can be calculated and will be used in inference. \n",
    "\n",
    "For example, how do we know the average height of males in this country is 5'9\"? \n",
    "If we were to draw one hundred different samples of 10 males at random, \n",
    "we will find a certain amount of difference among the means and standard deviationss of the samples.\n",
    "Imagine, that the standard deviation of our sample means is 2.25\", \n",
    "we have what is called the standard error of the mean. \n",
    "It can be defined as \"the theoretical standard deviation of sample means of a given sample drawn from a population\". \n",
    "\n",
    "When a researcher asserts something he/she is inferring, \n",
    "he/she does so with the knowledge that there will be a calculated error. \n",
    "They generally designate two cutoff points for error based upon normal distributions and they are called significance levels. \n",
    "Some researchers conclude that if the event would occur by chance 5% of time or less, then the event can be attributed to non-chance factors. \n",
    "In other settings, researchers conclude that if the event would occur by chance 1% of time or less, then the event can be attributed to non-chance factors. \n",
    "These are 0.5 significance level and 0.1 significance levels. \n",
    "The problem/data domain and other factors drive the required significance levels for a particular statistical evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example \n",
    "\n",
    "_\n",
    "In the case of male heights, we could choose at random 10 males and their average height would fall 69\" $\\pm$ 2.25\"(1.96) or 64.59 to 73.41. \n",
    "The sample standard deviation is multiplied by 1.96 since a z-score of $\\pm$1.96 would encompasses 95% of the normal distribution. \n",
    "Here if we are using 0.05 significance level we would theoretically be correct 95% of the time. \n",
    "Also, we would know that 5% of the samples we chose would have a mean height of greater than 73.41\" or less than 64.59\".\n",
    "_\n",
    "\n",
    "When dealing with two tailed tests, sometimes alpha levels/significance levels are referred to as confidence bands or confidence intervals. \n",
    "The 0.05 alpha level is 95% confidence band. \n",
    "You might say that you are 95% confident in asserting your hypothesis.\n",
    "\n",
    "\n",
    "In order to perform inferential statistics or parametric tests of significance, \n",
    "we'll have to use sampling distributions. \n",
    "In order to create a sampling distribution we would need to draw all possible samples of size N from a given population. \n",
    "Once we have calculated the mean for each distribution the resulting distribution would be the sampling distribution of means.\n",
    "\n",
    "Sampling distributions have 3 characteristics:\n",
    "* The mean of the sampling distribution will not change with a change in sample size. If the mean from the sampling distribution of means is 20 when N=10, it will remain 20 whether you increase or decrease the size of the samples. Simply put, the mean of the sampling distribution is equal to the mean of the population.\n",
    "* As the sample size in the sampling distribution of means increases, the dispersion of sample means will become less. The larger the N, the more compact the distribution of sample means. As N increases, standard error of the mean decreases.\n",
    "* If the sampling distribution of means is taken from a normally distributed population, the sample means will also be bell shaped.\n",
    "\n",
    "Based on above three issues, the **Central Limit Theorem** states: \n",
    "If random samples of fixed N are drawn from any population, as N becomes larger, \n",
    "the distribution of sample means approaches normality with the overall mean approaching $\\mu$.\n",
    "The standard error of the sample means is equal to\n",
    "\n",
    "$$\\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt(N)}$$\n",
    "\n",
    "and z-statistic is given as \n",
    "\n",
    "$$Z = \\frac{\\bar{X}-\\mu}{\\sigma_{\\bar{x}}}$$\n",
    "\n",
    "where,\n",
    "* $\\bar{X}$ = sample mean,\n",
    "* $\\mu$ = population mean and  \n",
    "* $\\sigma_{\\bar{x}}$ = sample standard deviation  \n",
    "\n",
    "\n",
    "\n",
    "**Reference:** [z-score](http://www.statisticshowto.com/probability-and-statistics/z-score/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypotheses\n",
    "\n",
    "_Null Hypothesis ($H_0$):_ \n",
    "The null hypothesis specifies values for parameters. \n",
    "Generally referred to as \"no significant difference\" hypothesis. \n",
    "Most analyses are set up to reject or not reject the Null hypothesis.\n",
    "\n",
    "_Alternate Hypothesis ($H_1$):_ \n",
    "The alternate hypothesis states that the population parameters are something other than the one hypothesized. \n",
    "A statement like \"this class is different from other statistics classes\" is example of an alternate hypothesis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical error (Type I, Alpha & Type II, Beta)\n",
    "\n",
    "_Type I_: \n",
    "When we reject null hypothesis and it is really true, it is called a Type I error. \n",
    "A Type I error is equal to the Alpha level set and sometimes referred to as an Alpha ($\\alpha$) error. \n",
    "If we set the alpha level at 0.5, our chance of making a Type I error is 5%. \n",
    "\n",
    "_Type II_: \n",
    "When we fail to reject the null hypothesis when it is actually false it is called a Type II error. \n",
    "This is also called beta ($\\beta$) error. \n",
    "\n",
    "**Note: ** \n",
    "A Type II error is more likely to be made than a Type I error. \n",
    "The lower we set the alpha level, \n",
    "the less likely we are to make a Type I error and more likely we are to make a Type II error. \n",
    "\n",
    "<img src=\"../images/hypothesis_test_results.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Let’s find out the inference with which we can draw from the body dimensions (_bdims_) data set we are going to work on. \n",
    "The dataset contains body dimensions data from 247 men and 260 women. \n",
    "\n",
    "Let’s say, we want to check the significance of variable `sex` for hypothesis testing. \n",
    "Assume that males (`sex=1`) have higher weight than the average population weight.\n",
    "\n",
    "To verify this assumption, let’s use z-test and see if males are actually heavier than the over all population.\n",
    "\n",
    "$H_0$: There is no significant difference in the weights of men and women\n",
    "\n",
    "$H_1$: There is a better chance of men being heavier than average population weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download.file(\"http://www.openintro.org/stat/data/bdims.RData\", destfile = \"bdims.RData\")\n",
    "load(\"bdims.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick peek into the first few rows of data...  \n",
    "Note that the weight (`wgt`) and `sex` are the last two columns of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head(bdims)\n",
    "summary(bdims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result you see that every observation has 25 measurements. \n",
    "The variable names description can be found at http://www.openintro.org/stat/data/bdims.php. \n",
    "We will work with just two columns for now: weight in kg (`wgt`) and `sex` (1 indicates male, 0 indicates female).\n",
    "\n",
    "Let's go ahead and create two different data sets: one for men and one for women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male <- subset(bdims, sex == 1)\n",
    "female <- subset(bdims, sex == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating Z-score\n",
    "\n",
    "A z-score is a measure of how many standard deviations below or above the population mean an observation is or the number of standard deviations from the mean a data point is. \n",
    "      \n",
    "Recall from the Introduction to Statistics for Analytics course (or boot camp), the descriptive statistics and dispersion concepts. \n",
    "Variance is the average difference squared from the mean; \n",
    "and standard deviation is then the square root of the variance.\n",
    "\n",
    "The below code computes some means, variances, z-scores, etc. of the dbims data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " sample_mean = mean(male$wgt)\n",
    " pop_mean = mean(bdims$wgt)\n",
    " pop_var = var(bdims$wgt)\n",
    " print(paste(\"sample mean : \",sample_mean))\n",
    " print(paste(\"population mean : \",pop_mean))\n",
    " print(paste(\"population variance : \",pop_var))\n",
    " zscore = (sample_mean - pop_mean) / (sqrt(pop_var)) #Standard Deviation\n",
    " print(paste(\"Z-score : \",zscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The below function calculates the z score\n",
    "#   You can write a function since R is just like any other programming language. \n",
    "#   This function evaluates the mean of the sample and the population, the standard deviation \n",
    "#    of population and calculates the z score.\n",
    "z.score = function(sam, pop){\n",
    " sample_mean = mean(sam)\n",
    " pop_mean = mean(pop)\n",
    " pop_var = var(pop)\n",
    " zscore = (sample_mean - pop_mean) / (sqrt(pop_var))\n",
    " return(zscore)\n",
    "}\n",
    "\n",
    "#call function\n",
    "#    We are using male weight below \n",
    "z.score(male$wgt, bdims$wgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The z score is 0.67 after rounding it to 2 decimals. \n",
    "Now we need to work out the percentage (or number) of men that weigh more and less than the population mean. \n",
    "We refer to the standard normal distribution table to find out this percentage value. \n",
    "\n",
    "![Standard Normal Distribution Table](../images/normal-table-large.png)\n",
    "\n",
    "To read the table, we break our z-score into two parts 0.67 = 0.6 (_tenths_) + 0.07 (_hundreths_)\n",
    "\n",
    "The tenths component is used to find the appropriate row in the table.  \n",
    "The hundreths component is used for the column. \n",
    "You then find the cell in the table for that row and column, and this represents the % of the population with a smaller value.\n",
    "\n",
    "Using the table, we can see that 74.86% of the population is lower than the average weight of men.\n",
    "\n",
    "This allows us to reject the Null Hypothesis, and therefore affirms our hypothesis, \n",
    "$H_1$ above, that males tend to weight more than the general population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_mean = mean(male$wgt)\n",
    "pop_mean = mean(bdims$wgt)\n",
    "pop_sd = sd(bdims$wgt)\n",
    "\n",
    "# Instead of a table, use R\n",
    "# probability under normal distribution for sample measure, mean, standard deviation.\n",
    "p = pnorm(sample_mean, mean=pop_mean, sd=pop_sd, lower.tail=TRUE) \n",
    "\n",
    "# Since p is a probability, we can confer this to a percentage;  \n",
    "print(paste(\"Probability=\",p))\n",
    "print(mean(male$wgt))\n",
    "print(mean(bdims$wgt))\n",
    "\n",
    "### UNCOMMENT THIS LINE TO READ DOCUMENTATION on pnorm, dnorm, etc.\n",
    "# help(pnorm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square analysis\n",
    "\n",
    "A non parametric test of significance is one that makes no assumption concerning the shape of the population distribution and is commonly referred to as a _distribution-free_ test of significance. \n",
    "Non parametric procedures are more suitable when data is categorical and for group comparison research.\n",
    "\n",
    "Chi square ($\\chi^2$) allows us to determine whether or not the proportion of observations \n",
    "within mutually exclusive categories differs significantly from the proportions expected by statistical chance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Goodness of Fit\n",
    "\n",
    "This is the one variable (univariate) case and is used to determine whether significant differences occur within a single group. \n",
    "The null hypothesis can be tested by applying the formula below. \n",
    "\n",
    "$$\\chi^2 = \\sum\\frac{(f_o - f_e)^2}{f_e}$$\n",
    "\n",
    "where,\n",
    "\n",
    "* $f_o$ = the observed number in a given category, and\n",
    "* $f_e$ = the expected number in that category\n",
    "\n",
    "For example, a psychology department at a university has three emphasis area options available for incoming students: clinical psychology, educational psychology and councelling psychology. \n",
    "If students were to just randomly select an area for study,\n",
    "probability would suggest that one-third would choose clinical psychology, \n",
    "one-third would choose educational psychology and one-third would choose councelling psychology. \n",
    "Let's say, there are 100 incoming students and 45 choose clinical psychology, \n",
    "30 choose educational psychology and 25 choose councelling psychology. \n",
    "Then, we can construct a set of hypothesis to determine if the selection of emphasis areas is random.\n",
    "We start with our Null Hypothesis and Alternative Hypothesis.\n",
    "\n",
    "$H_0$: No significant differences exist among students choosing academic options within psychology.\n",
    "\n",
    "$H_1$: Significant differences exist among students choosing academic options within psychology as compared to expectations (1/3 in each category).\n",
    "\n",
    "Test: $\\chi^2$\n",
    "\n",
    "$\\alpha$: 0.5\n",
    "\n",
    "Sampling Distribution: degrees of freedom: K-1 = 2      where K is the number of groups\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>Cell 1 <br> Clicinal <br> Psychology </td>\n",
    "<td>Cell 2 <br> Educational <br> Psychology </td>\n",
    "<td>Cell 3 <br> Councelling <br> Psychology </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>$f_o$=45 <br> $f_e$=33.3 </td>\n",
    "<td>$f_o$=30 <br> $f_e$=33.3 </td>\n",
    "<td>$f_o$=25 <br> $f_e$=33.3 </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "$$\\chi^2 = \\frac{(45 - 33.3)^2}{33.3} + \\frac{(30 - 33.3)^2}{33.3} + \\frac{(25 - 33.3)^2}{33.3}$$\n",
    "\n",
    "$$ = 4.10 + 0.33 + 2.08$$\n",
    "\n",
    "$$ = 6.51$$\n",
    "\n",
    "Decision: \n",
    "Since the calculated $\\chi^2$ value of 6.51 exceeds the table value of 5.991 we would reject the null hypothesis. \n",
    "  * [See Chi Square table here](http://www.itl.nist.gov/div898/handbook/eda/section3/eda3674.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Test of Independence\n",
    "\n",
    "Chi square test of independence of categorical variables is used when we describe differences between two or more groups in a two way table. \n",
    "It returns the probability for the computed chi-square distribution with the degree of freedom selected.\n",
    "\n",
    "Probability of 0: It indicates that both categorical variables are dependent.\n",
    "\n",
    "Probability of 1: It shows that both variables are independent.\n",
    "\n",
    "Probability less than 0.05: It indicates that the relationship between the variables is significant at 95% confidence.\n",
    "\n",
    "We will use the built-in function `chisq.test()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(chisq.test)\n",
    "chisq.test(c(bdims$wgt,bdims$sex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chisq.test(c(bdims$wgt, bdims$hgt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the **p values** in both cases are < 0.05,\n",
    "we can infer that height and sex are highly significant variables and must be included in our final data modeling stage.\n",
    "We should perform chi squared tests on other variables in the dataset to see if they are \n",
    "significant and should be included in any data modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation:\n",
    "\n",
    "Correlation determines the level of association between two variables. \n",
    "A scatter plot among the variables is one of the ways to find correlations between variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(bdims$wgt, bdims$hgt, xlab = 'weight', ylab = 'height')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a positive correlation among `hgt` and `wgt` variables. \n",
    "R has a built-in function to measure the correlation. \n",
    "Let's use the `cor.test()` function to verify that height and weight variables are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(cor.test)\n",
    "cor.test(bdims$wgt, bdims$hgt, method = 'pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the scatter plot suggests, the correlation function supports our assumption that height and weight are associated. \n",
    "The level of corelation is 0.717. \n",
    "\n",
    "You can perform tests on other variables in the dataset and similarly find associations among other variables. \n",
    "Variables that are highly correlated, e.g., 0.99 correlation, do not add much information to a predictive model. \n",
    "Therefore, when you have two indepedent variables that are highly correlated, you can usually drop one of these variables from your final model input design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This concludes the whirlwind review of descriptive and inferential statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
