{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6: Multi-class Support Vector Machine\n",
    "\n",
    "In this session, we fit a multi-class linear SVM on **red wine** dataset\n",
    "with the typical train/validate workflow.\n",
    "\n",
    "SVM only supports binary classification by itself.\n",
    "The multiclass support can be handled according to a **one-vs-one** or **one-vs-rest** scheme.\n",
    "Click [here](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.multiclass)\n",
    "to read more about different types of multiclass support schemes.\n",
    "\n",
    "Here we use the single class linear SVM from TensorFlow community contribution and construct\n",
    "a **one-vs-one multi-class SVM** based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset location\n",
    "DATASET = '/dsa/data/all_datasets/wine-quality/winequality-red.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "# Load and shuffle\n",
    "dataset = pd.read_csv(DATASET, sep=';').sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "# Pull features and labels\n",
    "selected_features = [1,6,9,10]\n",
    "X = scale(np.array(dataset.iloc[:, selected_features]))\n",
    "y = np.array(dataset.quality)\n",
    "\n",
    "# Create training/validation split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create multi-class SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array containing names of feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                             # code 20 is the space character\n",
    "feature_names = [dataset.columns[i].replace('\\x20', '_') for i in selected_features]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature columns, \n",
    "which are something conceptually similar to **TensorFlow placeholders**,\n",
    "that takes data from training loop.\n",
    "\n",
    "They must be fed training data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.contrib.layers.real_valued_column(i) for i in feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "One-vs-one multi-class SVM is essentially _a collection of binary linear SVMs_,\n",
    "each created for predicting a pair of classes against each other.\n",
    "\n",
    "Therefore for each pair of classes, there needs to be an SVM.\n",
    "In otherwords, given 4 classes {A,B,C,D}, there will need to be the following classifiers:\n",
    " * A vs B\n",
    " * A vs C\n",
    " * A vs D\n",
    " * B vs C\n",
    " * B vs D\n",
    " * C vs D\n",
    "\n",
    "Note: For $N$ classes, there will be ${N \\choose 2}$, \"N choose 2\", pair-wise classifiers.\n",
    "  * See: https://en.wikipedia.org/wiki/Binomial_coefficient\n",
    "\n",
    "Here we print out all classes with its distribution and all possible pair of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.unique(y_train)\n",
    "print('class distribution', {i:np.sum(y==i) for i in y_train})\n",
    "class_pairs = [(i,j) for i,j in itertools.product(class_labels, class_labels) if j>i]\n",
    "print('class pairs', class_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we traverse all pair of classes, and create an SVM dedicated to each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    pair: tf.contrib.learn.SVM('example_id', feature_columns=feature_columns, l2_regularization=1.0)\n",
    "        for pair in class_pairs\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly, we are going to need an `my_input_fn()` for each SVM. \n",
    "It's done by creating the following function that returns an `my_input_fn()` for any given pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_fn(pair):\n",
    "    # subset out all relevant data to this pair of classes.\n",
    "    sample = np.logical_or(y_train == pair[0], y_train == pair[1])\n",
    "    X_subset = X_train[sample, :]\n",
    "    y_subset = y_train[sample] == pair[1]\n",
    "    \n",
    "    # creating my_input_fn() that works on a subset of training data.\n",
    "    def my_input_fn():\n",
    "        columns = {\n",
    "            feature_name: tf.constant(np.expand_dims(X_subset[:, i], 1))\n",
    "                for i,feature_name in enumerate(feature_names)\n",
    "        }\n",
    "        columns['example_id'] = tf.constant([str(i+1) for i in range(len(X_subset))])\n",
    "        labels = tf.constant(y_subset)\n",
    "        return columns, labels\n",
    "    return my_input_fn, len(y_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit all SVM classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in class_pairs:\n",
    "    this_input_fn, sample_size = get_input_fn(pair)\n",
    "    print('Fitting an SVM to classes', pair, 'with', sample_size, 'samples.')\n",
    "    classifiers[pair].fit(input_fn = this_input_fn, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Below defines a set of functions that facilitates making predictions of this multi-class SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_pred_to_class(predictions, pair):\n",
    "    \"\"\" Convert SVM prediction into class labels\n",
    "           1. Take 'classes' attribute from each prediction\n",
    "           2. Use the binary prediction as index to find out original label from pair\n",
    "           \n",
    "        Example:\n",
    "            a prediction of 1 resulting from an SVM dedicated to classes (3, 4)\n",
    "            will be translated into 4, which is the original class label instead\n",
    "            of binary label 0 or 1.\n",
    "    \"\"\"\n",
    "    return list(map(lambda i: pair[i['classes']], predictions))\n",
    "\n",
    "def predict_fn():\n",
    "    \"\"\" Prepare test data from X_test \"\"\"\n",
    "    return {\n",
    "        feature_name: tf.constant(np.expand_dims(X_test[:, i], 1))\n",
    "            for i,feature_name in enumerate(feature_names)\n",
    "    }\n",
    "\n",
    "def vote(labels):\n",
    "    \"\"\" Aggregate prediction results from one-vs-one SVMs by counting votes per class \"\"\"\n",
    "    hist, bins = np.histogram(labels, class_labels)\n",
    "    return bins[np.argmax(hist)]\n",
    "\n",
    "def get_predictions(X_test): \n",
    "    \"\"\" Make predictions using all SVMs and aggregrate results. \"\"\"\n",
    "    \n",
    "    # Make predictions with all SVMs and stack results in columns.\n",
    "    #   This results in a matrix in shape (num_samples, num_class_pairs)\n",
    "    predictions = np.column_stack([\n",
    "        svm_pred_to_class(classifiers[pair].predict(input_fn = predict_fn), pair)\n",
    "            for pair in class_pairs])\n",
    "    print('predictions', predictions.shape)\n",
    "    \n",
    "    # Aggregate results along axis=1 into a final prediction for each sample.\n",
    "    return np.array([vote(row) for row in predictions])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a prediction on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = get_predictions(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy', accuracy_score(y_test, y_pred))\n",
    "plt.imshow(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your Notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
