{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6: Markov Chains\n",
    "\n",
    "A markov chain is a system whose evolution is described by a stochastic process.\n",
    "If the structure of such process is that dependence of current state with respect to entire past\n",
    "is completely captured by the dependence on the last sample, also know as the **Markov property**,\n",
    "then this process is a **Markov Chain**.\n",
    "\n",
    "The Markov property is mathetically expressed by the following [conditional independence](https://en.wikipedia.org/wiki/Conditional_independence):\n",
    "\n",
    "$$ P(X_{n+1}|X_n, X_{n-1}, ... X_1) = P(X_{n+1}|X_n) $$\n",
    "\n",
    "That is, the probability of next state within a process is the governed only by the current state.\n",
    "\n",
    "In this lab we will cover:\n",
    "* Transition probabilities of the Markov Chain\n",
    "* Ergodicity\n",
    "* Stationary distribution\n",
    "\n",
    "Here's more information on Markov Chains and live demos:\n",
    "http://setosa.io/ev/markov-chains/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: NumPy Linear Algebra Package\n",
    "\n",
    "This notebook uses the NumPy Linear Algebra package.\n",
    "It may be useful to revisit this documentation at a later date.\n",
    "\n",
    "This is necessary because we are getting into some more _fun_ math.\n",
    "The goal remains understanding concepts related to this tool and the type of \n",
    "data that can benefit from these types of models.\n",
    "\n",
    "You are encouraged to skip the math and come back to it later if you feel the need for an adventure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.linalg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example problem\n",
    "\n",
    "It's perhaps best to start with an example.\n",
    "![Markov Chain Example](../resources/mc1.png)\n",
    "\n",
    "Consider a radio station playing two genres of songs, which we label as 0 and 1.\n",
    "\n",
    "From time to time the radio station may switch genre or keep playing songs from the same genre.\n",
    "This graph gives the probabilty of whether such a switch takes place at any \n",
    "given time based on the current genre being played.\n",
    "\n",
    "These transition probabilities can be collected in a matrix, known as the transition matrix.\n",
    "\n",
    "$$P_{ij} = P(\\text{radio station switches genre from i to j}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Markov Chain can be used to anwser questions such as:\n",
    "* What's the probabilty of current state at any moment? (Or likelihood of each genre being played?)\n",
    "  * This is asking for the **stationary distribution**\n",
    "* What's the average time for the system to go back to each state? (Or how often does it play the same genre again?)\n",
    "\n",
    "To answer these questions, \n",
    "it's necessary to first realize that it's possible that some states could only occur\n",
    "a finite number of times i.e. there may be states that don't recur \n",
    "(usually due to topology of the graph).\n",
    "\n",
    "Here we only study the more generally meaningful case where\n",
    "\n",
    "$$ P(\\text{ever return to state i})=1 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A markov chain is said to be **ergodic** when we can substitute time averages for ensemble averages:\n",
    "\n",
    "$$ \\lim _ {k \\to \\infty } {\\frac{1}{\\frac{1}{k} \\sum_{k'=1}^{k}{T_i(k')} }} = \\frac {1}{E[T_i(k)]}$$\n",
    "\n",
    "where $T_i(k)$ is time elapses between (k-1)-th and k-th return to state i.\n",
    "\n",
    "The **ergodicity theorem** states that\n",
    "\n",
    "1. If a **stationary distribution** $\\pi$ exists for a Markov Chain, it's ergodic.\n",
    "2. Such **stationary distribution** is independent of initial distribution $\\pi_0$ of Markov Chain if it's ergodic.\n",
    "\n",
    "Therefore, assuming existence of a stationary distribution of the Markov Chain,\n",
    "the solution can be found using the **power method**:\n",
    "\n",
    "$$ \\pi = \\lim_{n \\to \\infty }{\\pi_0 P^{n}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the original problem, suppose the radio station has 1/3 probability \n",
    "of switching genre and 2/3 probability of staying in the same genre. \n",
    "\n",
    "Base on the fact that this is symmetric with respect to each genre, \n",
    "we should intuitively have probability of tuning into each genre equal to 1/2.\n",
    "\n",
    "Now let's solve using the power method and verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix\n",
    "P = np.array([[2/3, 1/3],\n",
    "              [1/3, 2/3]])\n",
    "\n",
    "# Initial distribution can be anything that sums up to 1\n",
    "pi0 = np.array([0.5, 0.5])\n",
    "\n",
    "# Compute stationary distribution - power method\n",
    "np.dot(pi0, np.linalg.matrix_power(P, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the probability of state 0 and 1 are both 0.5.\n",
    "\n",
    "But what if probability of switching from 0 to 1 is 1/4 and probability of switching from 1 to 0 is 1/3,\n",
    "so that this radio station baises towards one genre?\n",
    "\n",
    "We now can answer this less trivial question as well with the **power method**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix\n",
    "P = np.array([[3/4, 1/4], \n",
    "              [1/3, 2/3]])\n",
    "\n",
    "# Initial distribution can be anything that sums up to 1\n",
    "pi0 = np.array([0.5, 0.5])\n",
    "\n",
    "# Compute stationary state - power method\n",
    "np.dot(pi0, np.linalg.matrix_power(P, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a new probability of each genre given the changed transition probabilities.\n",
    "Intuitively, we are less likely to switch away from genre `0` to `1` than vice versa, \n",
    "and therefore more likely to hear a song from genre 0.\n",
    "\n",
    "\n",
    "Another tool for solving this problem is **eigen-decomposition** due to [Perron-Frobenius theorem](https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem).\n",
    "\n",
    "Let's compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some random 5x5 transition matrix\n",
    "P = np.random.rand(5, 5)\n",
    "P /= P.sum(axis=1)[:,np.newaxis] # normalization along axis 1\n",
    "\n",
    "# Compute stationary state - power method\n",
    "pi0 = np.random.rand(5)\n",
    "pi0 /= pi0.sum()\n",
    "a = np.dot(pi0, np.linalg.matrix_power(P, 50))\n",
    "print(a)\n",
    "\n",
    "# Compute stationary state - eigen decomposition\n",
    "L, Q = np.linalg.eig(P.T)\n",
    "# Pick eigenvector whose corresponding eigenvalue is closest to 1\n",
    "b = Q[:,np.argmin(abs(L - 1.0))].real\n",
    "# Normalize into a probability distribution\n",
    "b /= b.sum()\n",
    "print(b)\n",
    "\n",
    "np.allclose(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an implementation of the power method with **TensorFlow**.\n",
    "Currently neither matrix power or eigen-decomposition is supported,\n",
    "but we may still want to leverage TensorFlow's high scalibility to process datasets.\n",
    "\n",
    "This algorithm will use [divide and conquer](https://en.wikipedia.org/wiki/Divide_and_conquer_algorithm)\n",
    "strategy to reduce time complexity as well as\n",
    "space complexity for representing such computation in TensorFlow.\n",
    "\n",
    "The advantage is that this program will utilize GPU when available,\n",
    "and you wouldn't need to change anything to let that happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute stationary state - power method\n",
    "def mat_power(M, n):\n",
    "    \"\"\" Construct a graph that raises square matrix M to n-th power where n>=1\n",
    "    This generates a computational graph with space complexity O(log(n)).\n",
    "    \"\"\"\n",
    "    assert n>=1\n",
    "    # trivial cases\n",
    "    if n==2:\n",
    "        return tf.matmul(M, M)\n",
    "    elif n==1:\n",
    "        return M\n",
    "    \n",
    "    # divide & conquer\n",
    "    A = mat_power(M, n//2)\n",
    "    A2 = tf.matmul(A, A)\n",
    "    if n&1: # odd power\n",
    "        return tf.matmul(A2, M)\n",
    "    else: # even power\n",
    "        return A2\n",
    "\n",
    "def get_stationary_state(P):\n",
    "    pi0 = tf.constant(np.ones((1, len(P)))/len(P))\n",
    "    transition_matrix = tf.constant(P)\n",
    "    stationary_state = tf.squeeze(tf.matmul(pi0, mat_power(transition_matrix, 50)))\n",
    "    with tf.Session() as sess:\n",
    "        return sess.run(stationary_state)\n",
    "\n",
    "a = get_stationary_state(P)\n",
    "print(a)\n",
    "\n",
    "np.allclose(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your Notebook\n",
    "\n",
    "Now... read this!\n",
    "  * https://flowingdata.com/2015/12/15/a-day-in-the-life-of-americans/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
