{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6: Linear Support Vector Machine\n",
    "\n",
    "Support vector machine (SVM) is a linear _binary_ classifier.\n",
    "\n",
    "The goal of the SVM is to find a hyper-plane that separates the training data correctly\n",
    "into two subspaces while maximizing the **margin** between those two classes.\n",
    "\n",
    "![SVM](../resources/svm.png)\n",
    "\n",
    "The hyperplane satisfies\n",
    "\n",
    "$$ \\vec{w} \\cdot \\vec{x} - b = 1 $$\n",
    "\n",
    " * You will note, we again have a linear combination (dot-product) of weights and a data vector, adjusted by a bias.\n",
    "\n",
    "where $ \\vec{x} $ lies in feature space and $ \\vec{w} $ is the normal vector of the hyperplane.\n",
    "\n",
    "The constraint is formulated as:\n",
    "\n",
    "$$ y_i \\left(\\vec{w_i} \\cdot \\vec{x_i} - b \\right) \\ge 1 $$\n",
    "\n",
    "where $y$ is merely a mathematical convenience for writing down a unified inequality like so.\n",
    "Intuitively, it reflects all the negative samples along the hyperplane  so that all data points\n",
    "are bound by a single objective function. $y=1$ for all **positive samples**; $y=-1$ for **negative samples**.\n",
    "This implies that SVM is a **binary classifier**.\n",
    "\n",
    "The optimization results in miminizing $ \\left\\| w \\right\\| $ subject to constraint $ y_i \\left(\\vec{w_i} \\cdot \\vec{x_i} - b \\right) \\ge 1 $.\n",
    "\n",
    "The hyper-parameters for SVMs include the type of kernel and the regularization parameter C.  \n",
    "For linear SVM the kernel would be linear or we can say there's no kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "\n",
    "We will first generate 1000 random points.\n",
    "The line separating \"positive\" cases from negative cases is $y = x$.\n",
    "We compute the class of each (x, y) point as y > x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(-5, 5, (1000, 2))\n",
    "y = np.greater(X[:, 1], X[:, 0]).astype(int)\n",
    "\n",
    "# First look\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we separate points by a corridor of width $2\\sqrt{2}$ by adding vector $(1, -1)$ to points in class 0,\n",
    "and adding $(-1, 1)$ to points in class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[y==0] += np.array([1, -1])\n",
    "X[y==1] += np.array([-1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us quickly visualize what we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Function\n",
    "\n",
    "The job of the **input function** is to feed data into SVM.\n",
    "It is common to all contributed Estimator classes in TensorFlow.\n",
    "In case of SVM we need to provide a column that specifies the ID for each training data.\n",
    "In our trivial examples (which makes it easy to visualize it) we use points on a 2D plane.\n",
    "In a more complex applications you could have a much higher dimentionality data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_input_fn():\n",
    "    columns = dict(\n",
    "      # example_id is index for data records as required by the SVM,\n",
    "      #   anything uniquely identify each record is fine.\n",
    "      example_id = tf.constant([str(i+1) for i in range(len(X))]),\n",
    "    \n",
    "      # use a tf.constant to hold dataset. They need to be rank 2 tensors (in shape of matrices)\n",
    "      x = tf.constant(np.reshape(X[:, 0], [len(X), 1])),\n",
    "      y = tf.constant(np.reshape(X[:, 1], [len(X), 1])))\n",
    "    labels = tf.constant(y)\n",
    "    return columns, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVM\n",
    "\n",
    "Now we create two feature columns and define the SVM classifier.\n",
    "\n",
    "The name of the two feature columns should correspond to what's defined in the dictionary,\n",
    "that `my_input_fn()` would return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature1 = tf.contrib.layers.real_valued_column('x')\n",
    "feature2 = tf.contrib.layers.real_valued_column('y')\n",
    "\n",
    "# Define a classifier object that is an SVM\n",
    "svm_classifier = tf.contrib.learn.SVM(\n",
    "    feature_columns=[feature1, feature2],  #specify the feature columns\n",
    "    example_id_column='example_id')        #specify the label column\n",
    "\n",
    "svm_classifier.fit(input_fn=my_input_fn, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a quick evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = svm_classifier.evaluate(input_fn=my_input_fn, steps=1)\n",
    "print(\"Loss\", metrics['loss'], \"\\nAccuracy\", metrics['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting labels\n",
    "\n",
    "Once SVM classifier has been trained, we can use it to predict classes for n-dimentional (2 in our case) points.\n",
    "\n",
    "We create another function, predict_fn() that returns some data that we want the trained SVM to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.random.uniform(-5, 5, (60, 2))\n",
    "# Color by classification results\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X2[:, 0], X2[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn():\n",
    "    return dict(\n",
    "        x = tf.constant(np.expand_dims(X2[:, 0], 1)),\n",
    "        y = tf.constant(np.expand_dims(X2[:, 1], 1))\n",
    "    )\n",
    "\n",
    "# The following statement returns a generator that generates data in such structure:\n",
    "#    {'logits': array([-1.58874238]), 'classes': 0}\n",
    "#      ^^^ probability in log scale     ^^^ class label\n",
    "y_pred = svm_classifier.predict(input_fn=predict_fn)\n",
    "\n",
    "# just change of format: for each item i, take its i['classes']\n",
    "y_pred = list(map(lambda i: i['classes'], y_pred))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color by classification results\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X2[:, 0], X2[:, 1], c = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
