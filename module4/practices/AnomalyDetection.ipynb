{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Module 4: Anomaly Detection\n",
    "## Practice: Outlier Reduction for Linear Regression\n",
    "In this session, we'll be fitting a `LinearRegression` model on the `boston` dataset included in `scikit-learn`.  \n",
    "\n",
    "Having already worked with this dataset,\n",
    "you may remember it as a simple yet broadly representative linear regression problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started - imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset\n",
    "\n",
    "First order of business is to load in the dataset.  \n",
    "Run the following cell to load the boston dataset and get a description of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load boston housing dataset\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preparatory processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select out just a few of the features \n",
    "# NOX      nitric oxides concentration (parts per 10 million)\n",
    "# AGE      proportion of owner-occupied units built prior to 1\n",
    "# RAD      index of accessibility to radial highways\n",
    "# PTRATIO  pupil-teacher ratio by town\n",
    "# LSTAT    % lower status of the population\n",
    "boston_X = boston.data[:,(4,6,8,10,12)]\n",
    "boston_y = boston.target\n",
    "dataset = pd.DataFrame(np.column_stack([boston_X, boston_y])).sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "# Here's how to do the same with pandas\n",
    "# boston_X = pd.DataFrame(boston.data[:,(4,6,8,10,12)])\n",
    "# boston_y = pd.DataFrame(boston.target)\n",
    "# dataset = pd.concat([boston_X, boston_y], axis=1, join_axes=[boston_X.index]).sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "dataset.columns = ['NOX', 'AGE', 'RAD', 'PTRATIO', 'LSTAT', 'TARGET']\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull columns from dataset into variables X (everything except TARGET) and y (TARGET)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into X and y sets (use indices 4,6,8,10,12 for X)\n",
    "\n",
    "# Complete code below this comment  (Question #P4001)\n",
    "# ----------------------------------\n",
    "X = np.array(<placeholder>)\n",
    "y = np.array(<placeholder>)\n",
    "\n",
    "# Print out some basic shape data on the arrays\n",
    "print(\"X, y shape:\", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Create training/validation split** with 30% data held out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Complete code below this comment  (Question #P4002)\n",
    "# ----------------------------------\n",
    "<placeholder> = train_test_split(<placeholder>)\n",
    "\n",
    "# verify split shapes and contents\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run cross validation on a linear ridge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_model = Ridge()\n",
    "\n",
    "# Complete code below this comment  (Question #P4003)\n",
    "# ----------------------------------\n",
    "scores = cross_val_score(<placeholder>)\n",
    "print(\"Scores: \", scores)\n",
    "print(\"Mean score (3 folds): \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit this model on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete code below this comment  (Question #P4004)\n",
    "# ----------------------------------\n",
    "naive_model.fit(<placeholder>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some predictions from testing dataset and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete code below this comment  (Question #P4005)\n",
    "# ----------------------------------\n",
    "naive_predictions = naive_model.predict(<placeholder>)\n",
    "print(X_test.shape, naive_predictions.shape)\n",
    "plt.scatter(y_test, naive_predictions)\n",
    "\n",
    "# Fit a trendline for visualization\n",
    "z = np.polyfit(y_test, naive_predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.title(\"Predicted vs. actual target values\")\n",
    "plt.xlabel(\"Actual y value\")\n",
    "plt.ylabel(\"Model y value\")\n",
    "plt.plot(y_test, p(y_test), 'k--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues with the above model\n",
    "It is worth noting that without outlier reduction / anomaly detection in the pipeline, \n",
    "performance is relatively low. \n",
    "The actual performance on the test set is only scarcely better than random guessing \n",
    "(we can assume a baseline performance of 50% in such a case, and the model scores about 70%).\n",
    "\n",
    "## Why a trendline?\n",
    "This is mainly for illustrative purposes. \n",
    "The highest-error estimations are those farthest from the trendline, and ideally, \n",
    "the line of best fit would be `f(x) = x` \n",
    "(that is, the estimate and actual values would be perfectly equal in all cases).\n",
    "\n",
    "## What methods are available to us for outlier reduction?\n",
    "We could try `KMeans` or an `EllipticEnvelope` again, but we're going to explore a few more options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Construct IsolationForest \n",
    "iso_forest = IsolationForest(n_estimators=250,\n",
    "                             bootstrap=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(IsolationForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carefully read through the API documentation for Isolation Forest!\n",
    "\n",
    "Pull **inliers** into variables X_iso and y_iso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get labels from classifier and be ready to cull outliers\n",
    "iso_outliers = iso_forest.predict(X)==-1\n",
    "\n",
    "# Complete code below this comment  (Question #P4006)\n",
    "# ----------------------------------\n",
    "X_iso = <placeholder>\n",
    "y_iso = <placeholder>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can of course run a train-test split on the separated data as well\n",
    "X_train_iso, X_test_iso, y_train_iso, y_test_iso = train_test_split(X_iso, \n",
    "                                                                    y_iso, \n",
    "                                                                    test_size=0.3)\n",
    "# Fit the new model using the IsolationForest training split\n",
    "iso_model = Ridge()\n",
    "iso_model.fit(X_train_iso, y_train_iso)\n",
    "\n",
    "# Cross validate the new model\n",
    "iso_scores = cross_val_score(estimator=iso_model, \n",
    "                             X=X_test_iso, y=y_test_iso)\n",
    "print(iso_scores)\n",
    "print(\"Mean CV score w/ IsolationForest:\", np.mean(iso_scores))\n",
    "\n",
    "iso_predictions = iso_model.predict(X_test)\n",
    "\n",
    "# Plot the inlying points\n",
    "plt.scatter(y_test, iso_predictions)\n",
    "\n",
    "# Fit a trendline for visualization\n",
    "z = np.polyfit(y_test, iso_predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.title(\"Predicted vs. actual target values\")\n",
    "plt.xlabel(\"Actual y value\")\n",
    "plt.ylabel(\"Model y value\")\n",
    "plt.plot(y_test, p(y_test), 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Alternatives to IsolationForest: OneClassSVM\n",
    "This means it's time to try something else.  \n",
    "The code below will look very similar to the above, but using `OneClassSVM` in place of the `IsolationForest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "help(OneClassSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct OneClassSVM (kernel='rbf') and fit to full dataset\n",
    "svm = OneClassSVM(kernel='rbf').fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mark outliers.\n",
    "Pull **inliers** into variables X_svm and y_svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete code below this comment  (Question #P4007)\n",
    "# ----------------------------------\n",
    "\n",
    "# Get labels from classifier and mark outliers\n",
    "svm_outliers = <placeholder>\n",
    "\n",
    "# Pull inliers\n",
    "X_svm = <placeholder>\n",
    "y_svm = <placeholder>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_svm, y_svm, test_size=0.3)\n",
    "\n",
    "svm_model = Ridge().fit(X_train_svm, y_train_svm)\n",
    "\n",
    "# Cross validate the new model\n",
    "iso_scores = cross_val_score(estimator=svm_model, \n",
    "                             X=X_test_svm, y=y_test_svm)\n",
    "print(iso_scores)\n",
    "print(\"Mean CV score w/ OneClassSVM:\", np.mean(iso_scores))\n",
    "\n",
    "# Make predictions with the fitted model\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Plot the inlying points\n",
    "plt.scatter(y_test, svm_predictions)\n",
    "\n",
    "# Fit a trendline for visualization\n",
    "z = np.polyfit(y_test, svm_predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.title(\"Predicted vs. actual target values\")\n",
    "plt.xlabel(\"Actual y value\")\n",
    "plt.ylabel(\"Model y value\")\n",
    "plt.plot(y_test, p(y_test), 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Analysis\n",
    "\n",
    "Of the anomaly detection algorithms used, \n",
    "which had the highest marginal performance? \n",
    "Consider computational cost, which ones seemd to run fast versus slow?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Provide your answers to the question above in this cell\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further: performance analysis w/ `scikit` modules\n",
    "Compute and display the following for the models produced by each anomaly detection method:\n",
    " 1. Confusion Matrix\n",
    " 1. Accuracy\n",
    " 1. Precision\n",
    " 1. $F_1$-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your code for the above tasks here:   (Question #P4008)\n",
    "#  Ridge\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your code for the above tasks here:   (Question #P4009)\n",
    "#  IsolationForest\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your code for the above tasks here:   (Question #P4010)\n",
    "#  OneClassSVM\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
