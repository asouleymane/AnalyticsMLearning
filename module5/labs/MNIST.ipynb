{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Module 5: MNIST handwritten digits\n",
    "\n",
    "In this lab, we are going to learn to recognize hand-written digits from the MNIST data set.\n",
    "\n",
    "This dataset is the \"IRIS\" data of neural networks.\n",
    " * http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools, functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale, LabelBinarizer\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random seed for numpy\n",
    "np.random.seed(18937)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Keras\n",
    "\n",
    "Keras is an abstraction of the TensorFlow API to facilitate more easily constructed models.\n",
    "And actually, it is a general Python library for model construction that support TensorFlow and some other underlying lirbaries. \n",
    "  * https://keras.io/\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense, Dropout, Reshape\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we construct a [Convolutional Neural Network](http://deeplearning.net/tutorial/lenet.html) that has the following structure:\n",
    "  * Convolution with 5x5 pixel kernels, 32 of them, and using the [Rectified Linear Unit](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n",
    "  * Max Pooling with 2x2 kernel: Find the strongest response in each 2x2 neuron area of a generated feature map (from the convolution)\n",
    "     * Good Pooling Page: http://ufldl.stanford.edu/tutorial/supervised/Pooling/\n",
    "  * Convolve with 64 5x5 kernels, then Max Pooling again\n",
    "  * Strecth all the feature maps out into a vector\n",
    "  * A feed forward, fully connected layer -- think just dense vector -- of 1024 neurons\n",
    "  * 10 class activation using SoftMax, a logit layer, with all neurons normalized to sum to 1.0\n",
    "    * https://en.wikipedia.org/wiki/Softmax_function\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [   \n",
    "    Input(shape=(784,)),\n",
    "    Reshape((28, 28, 1)),\n",
    "    \n",
    "    # Convolutional network\n",
    "    Conv2D(32, (5, 5), activation='relu', padding='SAME'),\n",
    "    MaxPooling2D((2,2), strides=(2,2), padding='SAME'),\n",
    "    Conv2D(64, (5, 5), activation='relu', padding='SAME'),\n",
    "    MaxPooling2D((2,2), strides=(2,2), padding='SAME'),\n",
    "        \n",
    "    # Fully connected network\n",
    "    Reshape((7*7*64,)),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax'),\n",
    "]\n",
    "\n",
    "y_pred = functools.reduce(lambda f1, f2: f2(f1), layers)\n",
    "\n",
    "model = Model(inputs = [layers[0]], outputs = [y_pred])\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials import mnist\n",
    "dataset = mnist.input_data.read_data_sets('/dsa/data/all_datasets/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=[dataset.train.images], y=[dataset.train.labels], batch_size=50, epochs=10,\n",
    "      validation_data=(dataset.validation.images, dataset.validation.labels), shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluation')\n",
    "print('loss: %.4f  accuracy: %.4f' %\n",
    "      tuple(model.evaluate(x=[dataset.test.images], y=[dataset.test.labels], batch_size=50, verbose=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Save your notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
