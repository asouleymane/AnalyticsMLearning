{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: Transfer learning - Exercise\n",
    "\n",
    "In this session, you will create a **deep convolutional neural network** (DCNN)\n",
    "to classify **Food100** dataset.\n",
    "\n",
    "More info on this dataset click [here](http://foodcam.mobi/dataset100.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools, functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "import tf_threads\n",
    "tfconfig = tf_threads.limit(tf, 2)\n",
    "session = tf.Session(config=tfconfig)\n",
    "K.set_session(session)\n",
    "\n",
    "import h5py\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense, Dropout, Reshape, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "\n",
    "Here's directory structure for this dataset:\n",
    "~~~\n",
    "UECFOOD100/\n",
    "    1/     <<< these folders are category ids\n",
    "        1.jpg\n",
    "        2.jpg\n",
    "        3.jpg\n",
    "        ...\n",
    "    2/\n",
    "    ...\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET = lambda fname = '': os.path.join('/dsa/data/all_datasets/transfer_learning/UECFOOD100', fname)\n",
    "assert os.path.exists(DATASET())\n",
    "\n",
    "plt.figure(); \n",
    "imshow(imread(DATASET('50/9376.jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a DCNN model based on VGG16\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Specify input shape (150, 150, 3)\n",
    "2. Create a VGG16 network\n",
    "2. Lock weights in VGG16\n",
    "3. Create a classifier very similar to what we did in the Transfer Learning practice\n",
    "  * the 1st dense layer will have **800** units of neuron with **relu** activation.\n",
    "  * the 2nd dense layer will have **100** unit of neuron with **softmax** activation.\n",
    "5. Initialize a **Model** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E5001)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile** model and print a model **summary**.\n",
    "\n",
    "* **categorical_crossentropy** as loss function\n",
    "* Adam optimizer with **learning rate = $1 \\times 10^{-4}$ **.\n",
    "* use only `['accuracy']` as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E5002)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a DCNN model using transfer learningÂ¶\n",
    "\n",
    "Create training and validation data generators.\n",
    "\n",
    "* set batch size = **20**\n",
    "* set image resolution to **(150,150)** (this is what target_size is referring to)\n",
    "* set class mode as **'categorical'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E5003)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit this DCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.fit_generator(\n",
    "        train_generator, steps_per_epoch = 11448 // BATCH_SIZE,\n",
    "        validation_data=validation_generator, validation_steps = 2913 // BATCH_SIZE,\n",
    "        epochs=1)\n",
    "except KeyboardInterrupt:\n",
    "    \"\"\"Select from top menu Kernel->Interrupt to quit training and\n",
    "    leave model parameters (or weights) as they are.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this weights of this model to **\"./weights_food100.h5\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E5004)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Evaluate this model. Use **validation_generator** to provide data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E5005)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a confusion matrix over all 100 categories for the model.\n",
    "\n",
    "Steps (for each batch):\n",
    "\n",
    "1. make a prediction for this batch with model.predict() on **X_test**.\n",
    "2. add true food category ids for this batch to **y_true_sparse**\n",
    "3. add predicted food category ids for this batch to **y_pred_sparse**\n",
    "\n",
    "**Note**: validation_generator is an infinite generator, so if you directly traverse it\n",
    "using a for-loop, it'd be an infinite loop.   \n",
    "Instead, we use itertools.islice() to slice off the first 100 batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_category_id(one_hot_encoding):\n",
    "    \"\"\" This function converts one-hot to sparse encoding,\n",
    "        which would be the same as category id for this dataset.\n",
    "        \n",
    "        Example:\n",
    "        >>> get_category_id(np.array([[0.1, 0.1, 0.8], [0.9, 0.1, 0.0]]))\n",
    "        [3, 1]\n",
    "    \"\"\"\n",
    "    return np.argmax(one_hot_encoding, axis=1) + 1\n",
    "\n",
    "# Sparse labels for creating the confusion matrix\n",
    "y_true_sparse = [] # true food category id\n",
    "y_pred_sparse = [] # predicted food category id\n",
    "\n",
    "for batch in itertools.islice(validation_generator, 100):\n",
    "    X_test, y_test = batch\n",
    "    # Add code below this comment to fill in y_true_sparse and y_pred_sparse\n",
    "    #     (Question #E5006)\n",
    "    # ----------------------------------\n",
    "    # 1. make a prediction for this batch\n",
    "    \n",
    "    \n",
    "    # 2. add true food category ids for this batch\n",
    "    \n",
    "    \n",
    "    # 3. add predicted food category ids for this batch\n",
    "    \n",
    "    \n",
    "    # ----------------------------------\n",
    "\n",
    "# Plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(confusion_matrix(y_true_sparse, y_pred_sparse))\n",
    "plt.title('Confution Matrix')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional \n",
    "You could create another model and try the weights we have trained for you over 50 epochs at  \n",
    "\"`/dsa/data/all_datasets/transfer_learning/UECFOOD100/weights_food100.h5`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert os.path.exists('/dsa/data/all_datasets/transfer_learning/UECFOOD100/weights_food100.h5')\n",
    "\n",
    "# Do whatever you want below this comment  (Question #E5007)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
