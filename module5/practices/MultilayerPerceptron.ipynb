{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: Multilayer Perceptron - Practice\n",
    "\n",
    "In this session, you will create a **Multilayer Perceptron** (MLP) model to practice on the **Iris** dataset,\n",
    "to get more familiarized with TensorFlow.\n",
    "\n",
    "TensorFlow API reference\n",
    "* [tf.placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    "* [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer)\n",
    "* [tf.train.AdamOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)\n",
    "* [tf.Session](https://www.tensorflow.org/api_docs/python/tf/Session)\n",
    "* [tf.layers.dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import tf_threads\n",
    "tfconfig = tf_threads.limit(tf, 2)\n",
    "\n",
    "from sklearn.preprocessing import scale, LabelBinarizer\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "**Pull** iris[\"data\"] into **X** and iris[\"target\"] into **y**.\n",
    "\n",
    "**Standardize** X using [sklearn.processing.scale()](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "# Add code below this comment  (Question #P5001)\n",
    "# ----------------------------------\n",
    "X = <placeholder>\n",
    "y = <placeholder>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "1. Create training/validation split **X_train, X_test, y_train, y_test** and hold out 5% of data.\n",
    "2. Print class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #P5002)\n",
    "# ----------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(<placeholder>)\n",
    "print('Class distribution:', {i: <placeholder> for i in np.unique(y)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MLP classifier\n",
    "\n",
    "1. Choose appropriate activation for **hidden_layer2** and **predictions**.\n",
    "2. Complete **feed_dict** to feed batch data into MLP inside fit() and predict() respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(object):\n",
    "    def __init__(self, session, features, labels):\n",
    "        hidden_layer = tf.layers.dense(features, 4, tf.tanh)\n",
    "        # Complete code below this comment  (Question #P5003)\n",
    "        # ----------------------------------\n",
    "        hidden_layer2 = tf.layers.dense(hidden_layer, 3, <placeholder>)\n",
    "        predictions = tf.layers.dense(hidden_layer2, 3, <placeholder>)\n",
    "        # ----------------------------------\n",
    "\n",
    "        # Loss function\n",
    "        loss = tf.losses.mean_squared_error(labels, tf.squeeze(predictions))\n",
    "\n",
    "        # An optimizer defines the operation for updating parameters within the model.\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.03)\n",
    "\n",
    "        # Training is defined as minimizing the loss function using gradient descent.\n",
    "        training = optimizer.minimize(loss)\n",
    "        \n",
    "        self.context = [session, training, loss, predictions]\n",
    "        \n",
    "    def fit(self, X_train, y_train, N_BATCH=32):\n",
    "        sess, training, loss, _  = self.context\n",
    "        label_encoding=LabelBinarizer()\n",
    "        label_encoding.fit(y)\n",
    "        \n",
    "        training_loss = []\n",
    "        for epoch in range(25):\n",
    "            epoch_loss = []\n",
    "            for i in range(0, X_train.shape[0], N_BATCH):\n",
    "                _, batch_loss = sess.run([training, loss], feed_dict={\n",
    "                # Add code below this comment  (Question #P5004)\n",
    "                # ----------------------------------\n",
    "                    features: <placeholder>,\n",
    "                    labels: <placeholder>\n",
    "                # ----------------------------------\n",
    "                })\n",
    "                epoch_loss.append(batch_loss)\n",
    "            training_loss.append(np.mean(epoch_loss))\n",
    "            print('epoch', epoch, 'loss:', training_loss[-1])\n",
    "        self.training_loss = training_loss\n",
    "        self.label_encoding = label_encoding\n",
    "        \n",
    "    def predict(self, X_test, N_BATCH=32):\n",
    "        sess, _, _, predictions  = self.context\n",
    "        \n",
    "        y_pred = []\n",
    "        for i in range(0, X_test.shape[0], N_BATCH):\n",
    "            batch_prediction = sess.run(predictions, feed_dict={\n",
    "            # Complete code below this comment  (Question #P5004)\n",
    "            # ----------------------------------\n",
    "                features: <placeholder>\n",
    "            # ----------------------------------\n",
    "            })\n",
    "            class_probablity = self.label_encoding.inverse_transform(np.exp(batch_prediction))\n",
    "            y_pred.extend(class_probablity)\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model and plot confusion matrix\n",
    "\n",
    "0. Complete **features** shape\n",
    "1. Fit MLP model on (X_train, y_train)\n",
    "2. Make prediction on (X_test)\n",
    "3. Measure accuracy score on (y_test, y_pred)\n",
    "4. Complete comfusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete code below this comment  (Question #P5005)\n",
    "# ----------------------------------\n",
    "\n",
    "with tf.Session(config=tfconfig) as sess:\n",
    "    features = tf.placeholder(\"float\", (None, <placeholder>))\n",
    "    labels = tf.placeholder(\"float\", (None, 3))\n",
    "    mlp = MultilayerPerceptron(sess, features, labels)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    mlp.fit(<placeholder>)\n",
    "    \n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title('loss')\n",
    "    plt.plot(range(len(mlp.training_loss)), mlp.training_loss)\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    y_pred = mlp.predict(<placeholder>)\n",
    "    print('accuracy', <placeholder>)\n",
    "    plt.imshow(confusion_matrix(<placeholder>))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Save your notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
